2064['cache-misses', 'spark.reducer.maxSizeInFlight']
['cache-misses', 'spark.shuffle.file.buffer']
['cache-misses', 'spark.shuffle.memoryFraction']
['cache-misses', 'spark.shuffle.sort.bypassMergeThreshold']
['cache-misses', 'spark.speculation.interval']
['cache-misses', 'spark.speculation.multiplier']
['cache-misses', 'spark.speculation.quantile']
['cache-misses', 'spark.broadcast.blockSize']
['cache-misses', 'spark.io.compression.codec']
['cache-misses', 'spark.io.compression.lz4.blockSize']
['cache-misses', 'spark.io.compression.snappy.blockSize']
['cache-misses', 'spark.kryo.referenceTracking']
['cache-misses', 'spark.kryoserializer.buffer.max']
['cache-misses', 'spark.kryoserializer.buffer']
['cache-misses', 'spark.driver.cores']
['cache-misses', 'spark.executor.cores']
['cache-misses', 'spark.driver.memory']
['cache-misses', 'spark.executor.memory']
['cache-misses', 'spark.storage.memoryFraction']
['cache-misses', 'spark.storage.memoryMapThreshold']
['cache-misses', 'spark.storage.unrollFraction']
['cache-misses', 'spark.network.timeout']
['cache-misses', 'spark.locality.wait']
['cache-misses', 'spark.scheduler.revive.interval']
['cache-misses', 'spark.task.maxFailures']
['cache-misses', 'spark.shuffle.compress']
['cache-misses', 'spark.memory.fraction']
['cache-misses', 'spark.shuffle.spill.compress']
['cache-misses', 'spark.speculation']
['cache-misses', 'spark.broadcast.compress']
['cache-misses', 'spark.rdd.compress']
['cache-misses', 'spark.serializer']
['cache-misses', 'spark.memory.storageFraction']
['cache-misses', 'spark.default.parallelism']
['cache-misses', 'spark.memory.offHeap.enabled']
['cache-misses', 'spark.memory.offHeap.size']
['cache-misses', 'spark.executor.instances']
['cache-misses', 'spark.python.worker.memory']
['cache-misses', 'spark.python.worker.reuse']
['cache-misses', 'spark.rpc.message.maxSize']
['cache-misses', 'spark.driver.maxResultSize']
['cache-misses', 'spark.driver.memoryOverhead']
['cache-misses', 'spark.reducer.maxReqsInFlight']
['cache-misses', 'spark.reducer.maxBlocksInFlightPerAddress']
['cache-misses', 'spark.maxRemoteBlockSizeFetchToMem']
['cache-misses', 'spark.shuffle.io.maxRetries']
['cache-misses', 'spark.shuffle.io.numConnectionsPerPeer']
['cache-misses', 'spark.shuffle.io.preferDirectBufs']
['cache-misses', 'spark.shuffle.io.backLog']
['cache-misses', 'spark.shuffle.service.index.cache.size']
['cache-misses', 'spark.shuffle.maxChunksBeingTransferred']
['cache-misses', 'spark.serializer.objectStreamReset']
['cache-misses', 'spark.memory.useLegacyMode']
['cache-misses', 'spark.storage.replication.proactive']
['cache-misses', 'spark.cleaner.periodicGC.interval']
['cache-misses', 'spark.cleaner.referenceTracking']
['cache-misses', 'spark.cleaner.referenceTracking.blocking']
['cache-misses', 'spark.cleaner.referenceTracking.blocking.shuffle']
['cache-misses', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['cache-misses', 'spark.broadcast.checksum']
['cache-misses', 'spark.executor.heartbeatInterval']
['cache-misses', 'spark.files.fetchTimeout']
['cache-misses', 'spark.files.useFetchCache']
['cache-misses', 'spark.files.overwrite']
['cache-misses', 'spark.files.maxPartitionBytes']
['cache-misses', 'spark.files.openCostInBytes']
['cache-misses', 'spark.storage.memoryMapThreshold.1']
['cache-misses', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['cache-misses', 'spark.rpc.io.backLog']
['cache-misses', 'spark.port.maxRetries']
['cache-misses', 'spark.rpc.numRetries']
['cache-misses', 'spark.rpc.retry.wait']
['cache-misses', 'spark.rpc.lookupTimeout']
['cache-misses', 'spark.scheduler.minRegisteredResourcesRatio']
['cache-misses', 'spark.scheduler.mode']
['cache-misses', 'spark.scheduler.listenerbus.eventqueue.capacity']
['cache-misses', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['cache-misses', 'spark.task.reaper.enabled']
['cache-misses', 'spark.task.reaper.pollingInterval']
['cache-misses', 'spark.task.reaper.threadDump']
['cache-misses', 'spark.stage.maxConsecutiveAttempts']
['cache-misses', 'spark.streaming.backpressure.enabled']
['cache-misses', 'spark.streaming.blockInterval']
['cache-misses', 'spark.streaming.receiver.writeAheadLog.enable']
['cache-misses', 'spark.streaming.unpersist']
['cache-misses', 'spark.streaming.stopGracefullyOnShutdown']
['L1-dcache-load-misses', 'spark.reducer.maxSizeInFlight']
['L1-dcache-load-misses', 'spark.shuffle.file.buffer']
['L1-dcache-load-misses', 'spark.shuffle.memoryFraction']
['L1-dcache-load-misses', 'spark.shuffle.sort.bypassMergeThreshold']
['L1-dcache-load-misses', 'spark.speculation.interval']
['L1-dcache-load-misses', 'spark.speculation.multiplier']
['L1-dcache-load-misses', 'spark.speculation.quantile']
['L1-dcache-load-misses', 'spark.broadcast.blockSize']
['L1-dcache-load-misses', 'spark.io.compression.codec']
['L1-dcache-load-misses', 'spark.io.compression.lz4.blockSize']
['L1-dcache-load-misses', 'spark.io.compression.snappy.blockSize']
['L1-dcache-load-misses', 'spark.kryo.referenceTracking']
['L1-dcache-load-misses', 'spark.kryoserializer.buffer.max']
['L1-dcache-load-misses', 'spark.kryoserializer.buffer']
['L1-dcache-load-misses', 'spark.driver.cores']
['L1-dcache-load-misses', 'spark.executor.cores']
['L1-dcache-load-misses', 'spark.driver.memory']
['L1-dcache-load-misses', 'spark.executor.memory']
['L1-dcache-load-misses', 'spark.storage.memoryFraction']
['L1-dcache-load-misses', 'spark.storage.memoryMapThreshold']
['L1-dcache-load-misses', 'spark.storage.unrollFraction']
['L1-dcache-load-misses', 'spark.network.timeout']
['L1-dcache-load-misses', 'spark.locality.wait']
['L1-dcache-load-misses', 'spark.scheduler.revive.interval']
['L1-dcache-load-misses', 'spark.task.maxFailures']
['L1-dcache-load-misses', 'spark.shuffle.compress']
['L1-dcache-load-misses', 'spark.memory.fraction']
['L1-dcache-load-misses', 'spark.shuffle.spill.compress']
['L1-dcache-load-misses', 'spark.speculation']
['L1-dcache-load-misses', 'spark.broadcast.compress']
['L1-dcache-load-misses', 'spark.rdd.compress']
['L1-dcache-load-misses', 'spark.serializer']
['L1-dcache-load-misses', 'spark.memory.storageFraction']
['L1-dcache-load-misses', 'spark.default.parallelism']
['L1-dcache-load-misses', 'spark.memory.offHeap.enabled']
['L1-dcache-load-misses', 'spark.memory.offHeap.size']
['L1-dcache-load-misses', 'spark.executor.instances']
['L1-dcache-load-misses', 'spark.python.worker.memory']
['L1-dcache-load-misses', 'spark.python.worker.reuse']
['L1-dcache-load-misses', 'spark.rpc.message.maxSize']
['L1-dcache-load-misses', 'spark.driver.maxResultSize']
['L1-dcache-load-misses', 'spark.driver.memoryOverhead']
['L1-dcache-load-misses', 'spark.reducer.maxReqsInFlight']
['L1-dcache-load-misses', 'spark.reducer.maxBlocksInFlightPerAddress']
['L1-dcache-load-misses', 'spark.maxRemoteBlockSizeFetchToMem']
['L1-dcache-load-misses', 'spark.shuffle.io.maxRetries']
['L1-dcache-load-misses', 'spark.shuffle.io.numConnectionsPerPeer']
['L1-dcache-load-misses', 'spark.shuffle.io.preferDirectBufs']
['L1-dcache-load-misses', 'spark.shuffle.io.backLog']
['L1-dcache-load-misses', 'spark.shuffle.service.index.cache.size']
['L1-dcache-load-misses', 'spark.shuffle.maxChunksBeingTransferred']
['L1-dcache-load-misses', 'spark.serializer.objectStreamReset']
['L1-dcache-load-misses', 'spark.memory.useLegacyMode']
['L1-dcache-load-misses', 'spark.storage.replication.proactive']
['L1-dcache-load-misses', 'spark.cleaner.periodicGC.interval']
['L1-dcache-load-misses', 'spark.cleaner.referenceTracking']
['L1-dcache-load-misses', 'spark.cleaner.referenceTracking.blocking']
['L1-dcache-load-misses', 'spark.cleaner.referenceTracking.blocking.shuffle']
['L1-dcache-load-misses', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['L1-dcache-load-misses', 'spark.broadcast.checksum']
['L1-dcache-load-misses', 'spark.executor.heartbeatInterval']
['L1-dcache-load-misses', 'spark.files.fetchTimeout']
['L1-dcache-load-misses', 'spark.files.useFetchCache']
['L1-dcache-load-misses', 'spark.files.overwrite']
['L1-dcache-load-misses', 'spark.files.maxPartitionBytes']
['L1-dcache-load-misses', 'spark.files.openCostInBytes']
['L1-dcache-load-misses', 'spark.storage.memoryMapThreshold.1']
['L1-dcache-load-misses', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['L1-dcache-load-misses', 'spark.rpc.io.backLog']
['L1-dcache-load-misses', 'spark.port.maxRetries']
['L1-dcache-load-misses', 'spark.rpc.numRetries']
['L1-dcache-load-misses', 'spark.rpc.retry.wait']
['L1-dcache-load-misses', 'spark.rpc.lookupTimeout']
['L1-dcache-load-misses', 'spark.scheduler.minRegisteredResourcesRatio']
['L1-dcache-load-misses', 'spark.scheduler.mode']
['L1-dcache-load-misses', 'spark.scheduler.listenerbus.eventqueue.capacity']
['L1-dcache-load-misses', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['L1-dcache-load-misses', 'spark.task.reaper.enabled']
['L1-dcache-load-misses', 'spark.task.reaper.pollingInterval']
['L1-dcache-load-misses', 'spark.task.reaper.threadDump']
['L1-dcache-load-misses', 'spark.stage.maxConsecutiveAttempts']
['L1-dcache-load-misses', 'spark.streaming.backpressure.enabled']
['L1-dcache-load-misses', 'spark.streaming.blockInterval']
['L1-dcache-load-misses', 'spark.streaming.receiver.writeAheadLog.enable']
['L1-dcache-load-misses', 'spark.streaming.unpersist']
['L1-dcache-load-misses', 'spark.streaming.stopGracefullyOnShutdown']
['branch-misses', 'spark.reducer.maxSizeInFlight']
['branch-misses', 'spark.shuffle.file.buffer']
['branch-misses', 'spark.shuffle.memoryFraction']
['branch-misses', 'spark.shuffle.sort.bypassMergeThreshold']
['branch-misses', 'spark.speculation.interval']
['branch-misses', 'spark.speculation.multiplier']
['branch-misses', 'spark.speculation.quantile']
['branch-misses', 'spark.broadcast.blockSize']
['branch-misses', 'spark.io.compression.codec']
['branch-misses', 'spark.io.compression.lz4.blockSize']
['branch-misses', 'spark.io.compression.snappy.blockSize']
['branch-misses', 'spark.kryo.referenceTracking']
['branch-misses', 'spark.kryoserializer.buffer.max']
['branch-misses', 'spark.kryoserializer.buffer']
['branch-misses', 'spark.driver.cores']
['branch-misses', 'spark.executor.cores']
['branch-misses', 'spark.driver.memory']
['branch-misses', 'spark.executor.memory']
['branch-misses', 'spark.storage.memoryFraction']
['branch-misses', 'spark.storage.memoryMapThreshold']
['branch-misses', 'spark.storage.unrollFraction']
['branch-misses', 'spark.network.timeout']
['branch-misses', 'spark.locality.wait']
['branch-misses', 'spark.scheduler.revive.interval']
['branch-misses', 'spark.task.maxFailures']
['branch-misses', 'spark.shuffle.compress']
['branch-misses', 'spark.memory.fraction']
['branch-misses', 'spark.shuffle.spill.compress']
['branch-misses', 'spark.speculation']
['branch-misses', 'spark.broadcast.compress']
['branch-misses', 'spark.rdd.compress']
['branch-misses', 'spark.serializer']
['branch-misses', 'spark.memory.storageFraction']
['branch-misses', 'spark.default.parallelism']
['branch-misses', 'spark.memory.offHeap.enabled']
['branch-misses', 'spark.memory.offHeap.size']
['branch-misses', 'spark.executor.instances']
['branch-misses', 'spark.python.worker.memory']
['branch-misses', 'spark.python.worker.reuse']
['branch-misses', 'spark.rpc.message.maxSize']
['branch-misses', 'spark.driver.maxResultSize']
['branch-misses', 'spark.driver.memoryOverhead']
['branch-misses', 'spark.reducer.maxReqsInFlight']
['branch-misses', 'spark.reducer.maxBlocksInFlightPerAddress']
['branch-misses', 'spark.maxRemoteBlockSizeFetchToMem']
['branch-misses', 'spark.shuffle.io.maxRetries']
['branch-misses', 'spark.shuffle.io.numConnectionsPerPeer']
['branch-misses', 'spark.shuffle.io.preferDirectBufs']
['branch-misses', 'spark.shuffle.io.backLog']
['branch-misses', 'spark.shuffle.service.index.cache.size']
['branch-misses', 'spark.shuffle.maxChunksBeingTransferred']
['branch-misses', 'spark.serializer.objectStreamReset']
['branch-misses', 'spark.memory.useLegacyMode']
['branch-misses', 'spark.storage.replication.proactive']
['branch-misses', 'spark.cleaner.periodicGC.interval']
['branch-misses', 'spark.cleaner.referenceTracking']
['branch-misses', 'spark.cleaner.referenceTracking.blocking']
['branch-misses', 'spark.cleaner.referenceTracking.blocking.shuffle']
['branch-misses', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['branch-misses', 'spark.broadcast.checksum']
['branch-misses', 'spark.executor.heartbeatInterval']
['branch-misses', 'spark.files.fetchTimeout']
['branch-misses', 'spark.files.useFetchCache']
['branch-misses', 'spark.files.overwrite']
['branch-misses', 'spark.files.maxPartitionBytes']
['branch-misses', 'spark.files.openCostInBytes']
['branch-misses', 'spark.storage.memoryMapThreshold.1']
['branch-misses', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['branch-misses', 'spark.rpc.io.backLog']
['branch-misses', 'spark.port.maxRetries']
['branch-misses', 'spark.rpc.numRetries']
['branch-misses', 'spark.rpc.retry.wait']
['branch-misses', 'spark.rpc.lookupTimeout']
['branch-misses', 'spark.scheduler.minRegisteredResourcesRatio']
['branch-misses', 'spark.scheduler.mode']
['branch-misses', 'spark.scheduler.listenerbus.eventqueue.capacity']
['branch-misses', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['branch-misses', 'spark.task.reaper.enabled']
['branch-misses', 'spark.task.reaper.pollingInterval']
['branch-misses', 'spark.task.reaper.threadDump']
['branch-misses', 'spark.stage.maxConsecutiveAttempts']
['branch-misses', 'spark.streaming.backpressure.enabled']
['branch-misses', 'spark.streaming.blockInterval']
['branch-misses', 'spark.streaming.receiver.writeAheadLog.enable']
['branch-misses', 'spark.streaming.unpersist']
['branch-misses', 'spark.streaming.stopGracefullyOnShutdown']
['msr/pperf/', 'spark.reducer.maxSizeInFlight']
['msr/pperf/', 'spark.shuffle.file.buffer']
['msr/pperf/', 'spark.shuffle.memoryFraction']
['msr/pperf/', 'spark.shuffle.sort.bypassMergeThreshold']
['msr/pperf/', 'spark.speculation.interval']
['msr/pperf/', 'spark.speculation.multiplier']
['msr/pperf/', 'spark.speculation.quantile']
['msr/pperf/', 'spark.broadcast.blockSize']
['msr/pperf/', 'spark.io.compression.codec']
['msr/pperf/', 'spark.io.compression.lz4.blockSize']
['msr/pperf/', 'spark.io.compression.snappy.blockSize']
['msr/pperf/', 'spark.kryo.referenceTracking']
['msr/pperf/', 'spark.kryoserializer.buffer.max']
['msr/pperf/', 'spark.kryoserializer.buffer']
['msr/pperf/', 'spark.driver.cores']
['msr/pperf/', 'spark.executor.cores']
['msr/pperf/', 'spark.driver.memory']
['msr/pperf/', 'spark.executor.memory']
['msr/pperf/', 'spark.storage.memoryFraction']
['msr/pperf/', 'spark.storage.memoryMapThreshold']
['msr/pperf/', 'spark.storage.unrollFraction']
['msr/pperf/', 'spark.network.timeout']
['msr/pperf/', 'spark.locality.wait']
['msr/pperf/', 'spark.scheduler.revive.interval']
['msr/pperf/', 'spark.task.maxFailures']
['msr/pperf/', 'spark.shuffle.compress']
['msr/pperf/', 'spark.memory.fraction']
['msr/pperf/', 'spark.shuffle.spill.compress']
['msr/pperf/', 'spark.speculation']
['msr/pperf/', 'spark.broadcast.compress']
['msr/pperf/', 'spark.rdd.compress']
['msr/pperf/', 'spark.serializer']
['msr/pperf/', 'spark.memory.storageFraction']
['msr/pperf/', 'spark.default.parallelism']
['msr/pperf/', 'spark.memory.offHeap.enabled']
['msr/pperf/', 'spark.memory.offHeap.size']
['msr/pperf/', 'spark.executor.instances']
['msr/pperf/', 'spark.python.worker.memory']
['msr/pperf/', 'spark.python.worker.reuse']
['msr/pperf/', 'spark.rpc.message.maxSize']
['msr/pperf/', 'spark.driver.maxResultSize']
['msr/pperf/', 'spark.driver.memoryOverhead']
['msr/pperf/', 'spark.reducer.maxReqsInFlight']
['msr/pperf/', 'spark.reducer.maxBlocksInFlightPerAddress']
['msr/pperf/', 'spark.maxRemoteBlockSizeFetchToMem']
['msr/pperf/', 'spark.shuffle.io.maxRetries']
['msr/pperf/', 'spark.shuffle.io.numConnectionsPerPeer']
['msr/pperf/', 'spark.shuffle.io.preferDirectBufs']
['msr/pperf/', 'spark.shuffle.io.backLog']
['msr/pperf/', 'spark.shuffle.service.index.cache.size']
['msr/pperf/', 'spark.shuffle.maxChunksBeingTransferred']
['msr/pperf/', 'spark.serializer.objectStreamReset']
['msr/pperf/', 'spark.memory.useLegacyMode']
['msr/pperf/', 'spark.storage.replication.proactive']
['msr/pperf/', 'spark.cleaner.periodicGC.interval']
['msr/pperf/', 'spark.cleaner.referenceTracking']
['msr/pperf/', 'spark.cleaner.referenceTracking.blocking']
['msr/pperf/', 'spark.cleaner.referenceTracking.blocking.shuffle']
['msr/pperf/', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['msr/pperf/', 'spark.broadcast.checksum']
['msr/pperf/', 'spark.executor.heartbeatInterval']
['msr/pperf/', 'spark.files.fetchTimeout']
['msr/pperf/', 'spark.files.useFetchCache']
['msr/pperf/', 'spark.files.overwrite']
['msr/pperf/', 'spark.files.maxPartitionBytes']
['msr/pperf/', 'spark.files.openCostInBytes']
['msr/pperf/', 'spark.storage.memoryMapThreshold.1']
['msr/pperf/', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['msr/pperf/', 'spark.rpc.io.backLog']
['msr/pperf/', 'spark.port.maxRetries']
['msr/pperf/', 'spark.rpc.numRetries']
['msr/pperf/', 'spark.rpc.retry.wait']
['msr/pperf/', 'spark.rpc.lookupTimeout']
['msr/pperf/', 'spark.scheduler.minRegisteredResourcesRatio']
['msr/pperf/', 'spark.scheduler.mode']
['msr/pperf/', 'spark.scheduler.listenerbus.eventqueue.capacity']
['msr/pperf/', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['msr/pperf/', 'spark.task.reaper.enabled']
['msr/pperf/', 'spark.task.reaper.pollingInterval']
['msr/pperf/', 'spark.task.reaper.threadDump']
['msr/pperf/', 'spark.stage.maxConsecutiveAttempts']
['msr/pperf/', 'spark.streaming.backpressure.enabled']
['msr/pperf/', 'spark.streaming.blockInterval']
['msr/pperf/', 'spark.streaming.receiver.writeAheadLog.enable']
['msr/pperf/', 'spark.streaming.unpersist']
['msr/pperf/', 'spark.streaming.stopGracefullyOnShutdown']
['topdown-slots-retired', 'spark.reducer.maxSizeInFlight']
['topdown-slots-retired', 'spark.shuffle.file.buffer']
['topdown-slots-retired', 'spark.shuffle.memoryFraction']
['topdown-slots-retired', 'spark.shuffle.sort.bypassMergeThreshold']
['topdown-slots-retired', 'spark.speculation.interval']
['topdown-slots-retired', 'spark.speculation.multiplier']
['topdown-slots-retired', 'spark.speculation.quantile']
['topdown-slots-retired', 'spark.broadcast.blockSize']
['topdown-slots-retired', 'spark.io.compression.codec']
['topdown-slots-retired', 'spark.io.compression.lz4.blockSize']
['topdown-slots-retired', 'spark.io.compression.snappy.blockSize']
['topdown-slots-retired', 'spark.kryo.referenceTracking']
['topdown-slots-retired', 'spark.kryoserializer.buffer.max']
['topdown-slots-retired', 'spark.kryoserializer.buffer']
['topdown-slots-retired', 'spark.driver.cores']
['topdown-slots-retired', 'spark.executor.cores']
['topdown-slots-retired', 'spark.driver.memory']
['topdown-slots-retired', 'spark.executor.memory']
['topdown-slots-retired', 'spark.storage.memoryFraction']
['topdown-slots-retired', 'spark.storage.memoryMapThreshold']
['topdown-slots-retired', 'spark.storage.unrollFraction']
['topdown-slots-retired', 'spark.network.timeout']
['topdown-slots-retired', 'spark.locality.wait']
['topdown-slots-retired', 'spark.scheduler.revive.interval']
['topdown-slots-retired', 'spark.task.maxFailures']
['topdown-slots-retired', 'spark.shuffle.compress']
['topdown-slots-retired', 'spark.memory.fraction']
['topdown-slots-retired', 'spark.shuffle.spill.compress']
['topdown-slots-retired', 'spark.speculation']
['topdown-slots-retired', 'spark.broadcast.compress']
['topdown-slots-retired', 'spark.rdd.compress']
['topdown-slots-retired', 'spark.serializer']
['topdown-slots-retired', 'spark.memory.storageFraction']
['topdown-slots-retired', 'spark.default.parallelism']
['topdown-slots-retired', 'spark.memory.offHeap.enabled']
['topdown-slots-retired', 'spark.memory.offHeap.size']
['topdown-slots-retired', 'spark.executor.instances']
['topdown-slots-retired', 'spark.python.worker.memory']
['topdown-slots-retired', 'spark.python.worker.reuse']
['topdown-slots-retired', 'spark.rpc.message.maxSize']
['topdown-slots-retired', 'spark.driver.maxResultSize']
['topdown-slots-retired', 'spark.driver.memoryOverhead']
['topdown-slots-retired', 'spark.reducer.maxReqsInFlight']
['topdown-slots-retired', 'spark.reducer.maxBlocksInFlightPerAddress']
['topdown-slots-retired', 'spark.maxRemoteBlockSizeFetchToMem']
['topdown-slots-retired', 'spark.shuffle.io.maxRetries']
['topdown-slots-retired', 'spark.shuffle.io.numConnectionsPerPeer']
['topdown-slots-retired', 'spark.shuffle.io.preferDirectBufs']
['topdown-slots-retired', 'spark.shuffle.io.backLog']
['topdown-slots-retired', 'spark.shuffle.service.index.cache.size']
['topdown-slots-retired', 'spark.shuffle.maxChunksBeingTransferred']
['topdown-slots-retired', 'spark.serializer.objectStreamReset']
['topdown-slots-retired', 'spark.memory.useLegacyMode']
['topdown-slots-retired', 'spark.storage.replication.proactive']
['topdown-slots-retired', 'spark.cleaner.periodicGC.interval']
['topdown-slots-retired', 'spark.cleaner.referenceTracking']
['topdown-slots-retired', 'spark.cleaner.referenceTracking.blocking']
['topdown-slots-retired', 'spark.cleaner.referenceTracking.blocking.shuffle']
['topdown-slots-retired', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['topdown-slots-retired', 'spark.broadcast.checksum']
['topdown-slots-retired', 'spark.executor.heartbeatInterval']
['topdown-slots-retired', 'spark.files.fetchTimeout']
['topdown-slots-retired', 'spark.files.useFetchCache']
['topdown-slots-retired', 'spark.files.overwrite']
['topdown-slots-retired', 'spark.files.maxPartitionBytes']
['topdown-slots-retired', 'spark.files.openCostInBytes']
['topdown-slots-retired', 'spark.storage.memoryMapThreshold.1']
['topdown-slots-retired', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['topdown-slots-retired', 'spark.rpc.io.backLog']
['topdown-slots-retired', 'spark.port.maxRetries']
['topdown-slots-retired', 'spark.rpc.numRetries']
['topdown-slots-retired', 'spark.rpc.retry.wait']
['topdown-slots-retired', 'spark.rpc.lookupTimeout']
['topdown-slots-retired', 'spark.scheduler.minRegisteredResourcesRatio']
['topdown-slots-retired', 'spark.scheduler.mode']
['topdown-slots-retired', 'spark.scheduler.listenerbus.eventqueue.capacity']
['topdown-slots-retired', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['topdown-slots-retired', 'spark.task.reaper.enabled']
['topdown-slots-retired', 'spark.task.reaper.pollingInterval']
['topdown-slots-retired', 'spark.task.reaper.threadDump']
['topdown-slots-retired', 'spark.stage.maxConsecutiveAttempts']
['topdown-slots-retired', 'spark.streaming.backpressure.enabled']
['topdown-slots-retired', 'spark.streaming.blockInterval']
['topdown-slots-retired', 'spark.streaming.receiver.writeAheadLog.enable']
['topdown-slots-retired', 'spark.streaming.unpersist']
['topdown-slots-retired', 'spark.streaming.stopGracefullyOnShutdown']
['cache-references', 'spark.reducer.maxSizeInFlight']
['cache-references', 'spark.shuffle.file.buffer']
['cache-references', 'spark.shuffle.memoryFraction']
['cache-references', 'spark.shuffle.sort.bypassMergeThreshold']
['cache-references', 'spark.speculation.interval']
['cache-references', 'spark.speculation.multiplier']
['cache-references', 'spark.speculation.quantile']
['cache-references', 'spark.broadcast.blockSize']
['cache-references', 'spark.io.compression.codec']
['cache-references', 'spark.io.compression.lz4.blockSize']
['cache-references', 'spark.io.compression.snappy.blockSize']
['cache-references', 'spark.kryo.referenceTracking']
['cache-references', 'spark.kryoserializer.buffer.max']
['cache-references', 'spark.kryoserializer.buffer']
['cache-references', 'spark.driver.cores']
['cache-references', 'spark.executor.cores']
['cache-references', 'spark.driver.memory']
['cache-references', 'spark.executor.memory']
['cache-references', 'spark.storage.memoryFraction']
['cache-references', 'spark.storage.memoryMapThreshold']
['cache-references', 'spark.storage.unrollFraction']
['cache-references', 'spark.network.timeout']
['cache-references', 'spark.locality.wait']
['cache-references', 'spark.scheduler.revive.interval']
['cache-references', 'spark.task.maxFailures']
['cache-references', 'spark.shuffle.compress']
['cache-references', 'spark.memory.fraction']
['cache-references', 'spark.shuffle.spill.compress']
['cache-references', 'spark.speculation']
['cache-references', 'spark.broadcast.compress']
['cache-references', 'spark.rdd.compress']
['cache-references', 'spark.serializer']
['cache-references', 'spark.memory.storageFraction']
['cache-references', 'spark.default.parallelism']
['cache-references', 'spark.memory.offHeap.enabled']
['cache-references', 'spark.memory.offHeap.size']
['cache-references', 'spark.executor.instances']
['cache-references', 'spark.python.worker.memory']
['cache-references', 'spark.python.worker.reuse']
['cache-references', 'spark.rpc.message.maxSize']
['cache-references', 'spark.driver.maxResultSize']
['cache-references', 'spark.driver.memoryOverhead']
['cache-references', 'spark.reducer.maxReqsInFlight']
['cache-references', 'spark.reducer.maxBlocksInFlightPerAddress']
['cache-references', 'spark.maxRemoteBlockSizeFetchToMem']
['cache-references', 'spark.shuffle.io.maxRetries']
['cache-references', 'spark.shuffle.io.numConnectionsPerPeer']
['cache-references', 'spark.shuffle.io.preferDirectBufs']
['cache-references', 'spark.shuffle.io.backLog']
['cache-references', 'spark.shuffle.service.index.cache.size']
['cache-references', 'spark.shuffle.maxChunksBeingTransferred']
['cache-references', 'spark.serializer.objectStreamReset']
['cache-references', 'spark.memory.useLegacyMode']
['cache-references', 'spark.storage.replication.proactive']
['cache-references', 'spark.cleaner.periodicGC.interval']
['cache-references', 'spark.cleaner.referenceTracking']
['cache-references', 'spark.cleaner.referenceTracking.blocking']
['cache-references', 'spark.cleaner.referenceTracking.blocking.shuffle']
['cache-references', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['cache-references', 'spark.broadcast.checksum']
['cache-references', 'spark.executor.heartbeatInterval']
['cache-references', 'spark.files.fetchTimeout']
['cache-references', 'spark.files.useFetchCache']
['cache-references', 'spark.files.overwrite']
['cache-references', 'spark.files.maxPartitionBytes']
['cache-references', 'spark.files.openCostInBytes']
['cache-references', 'spark.storage.memoryMapThreshold.1']
['cache-references', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['cache-references', 'spark.rpc.io.backLog']
['cache-references', 'spark.port.maxRetries']
['cache-references', 'spark.rpc.numRetries']
['cache-references', 'spark.rpc.retry.wait']
['cache-references', 'spark.rpc.lookupTimeout']
['cache-references', 'spark.scheduler.minRegisteredResourcesRatio']
['cache-references', 'spark.scheduler.mode']
['cache-references', 'spark.scheduler.listenerbus.eventqueue.capacity']
['cache-references', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['cache-references', 'spark.task.reaper.enabled']
['cache-references', 'spark.task.reaper.pollingInterval']
['cache-references', 'spark.task.reaper.threadDump']
['cache-references', 'spark.stage.maxConsecutiveAttempts']
['cache-references', 'spark.streaming.backpressure.enabled']
['cache-references', 'spark.streaming.blockInterval']
['cache-references', 'spark.streaming.receiver.writeAheadLog.enable']
['cache-references', 'spark.streaming.unpersist']
['cache-references', 'spark.streaming.stopGracefullyOnShutdown']
['L1-dcache-stores', 'spark.reducer.maxSizeInFlight']
['L1-dcache-stores', 'spark.shuffle.file.buffer']
['L1-dcache-stores', 'spark.shuffle.memoryFraction']
['L1-dcache-stores', 'spark.shuffle.sort.bypassMergeThreshold']
['L1-dcache-stores', 'spark.speculation.interval']
['L1-dcache-stores', 'spark.speculation.multiplier']
['L1-dcache-stores', 'spark.speculation.quantile']
['L1-dcache-stores', 'spark.broadcast.blockSize']
['L1-dcache-stores', 'spark.io.compression.codec']
['L1-dcache-stores', 'spark.io.compression.lz4.blockSize']
['L1-dcache-stores', 'spark.io.compression.snappy.blockSize']
['L1-dcache-stores', 'spark.kryo.referenceTracking']
['L1-dcache-stores', 'spark.kryoserializer.buffer.max']
['L1-dcache-stores', 'spark.kryoserializer.buffer']
['L1-dcache-stores', 'spark.driver.cores']
['L1-dcache-stores', 'spark.executor.cores']
['L1-dcache-stores', 'spark.driver.memory']
['L1-dcache-stores', 'spark.executor.memory']
['L1-dcache-stores', 'spark.storage.memoryFraction']
['L1-dcache-stores', 'spark.storage.memoryMapThreshold']
['L1-dcache-stores', 'spark.storage.unrollFraction']
['L1-dcache-stores', 'spark.network.timeout']
['L1-dcache-stores', 'spark.locality.wait']
['L1-dcache-stores', 'spark.scheduler.revive.interval']
['L1-dcache-stores', 'spark.task.maxFailures']
['L1-dcache-stores', 'spark.shuffle.compress']
['L1-dcache-stores', 'spark.memory.fraction']
['L1-dcache-stores', 'spark.shuffle.spill.compress']
['L1-dcache-stores', 'spark.speculation']
['L1-dcache-stores', 'spark.broadcast.compress']
['L1-dcache-stores', 'spark.rdd.compress']
['L1-dcache-stores', 'spark.serializer']
['L1-dcache-stores', 'spark.memory.storageFraction']
['L1-dcache-stores', 'spark.default.parallelism']
['L1-dcache-stores', 'spark.memory.offHeap.enabled']
['L1-dcache-stores', 'spark.memory.offHeap.size']
['L1-dcache-stores', 'spark.executor.instances']
['L1-dcache-stores', 'spark.python.worker.memory']
['L1-dcache-stores', 'spark.python.worker.reuse']
['L1-dcache-stores', 'spark.rpc.message.maxSize']
['L1-dcache-stores', 'spark.driver.maxResultSize']
['L1-dcache-stores', 'spark.driver.memoryOverhead']
['L1-dcache-stores', 'spark.reducer.maxReqsInFlight']
['L1-dcache-stores', 'spark.reducer.maxBlocksInFlightPerAddress']
['L1-dcache-stores', 'spark.maxRemoteBlockSizeFetchToMem']
['L1-dcache-stores', 'spark.shuffle.io.maxRetries']
['L1-dcache-stores', 'spark.shuffle.io.numConnectionsPerPeer']
['L1-dcache-stores', 'spark.shuffle.io.preferDirectBufs']
['L1-dcache-stores', 'spark.shuffle.io.backLog']
['L1-dcache-stores', 'spark.shuffle.service.index.cache.size']
['L1-dcache-stores', 'spark.shuffle.maxChunksBeingTransferred']
['L1-dcache-stores', 'spark.serializer.objectStreamReset']
['L1-dcache-stores', 'spark.memory.useLegacyMode']
['L1-dcache-stores', 'spark.storage.replication.proactive']
['L1-dcache-stores', 'spark.cleaner.periodicGC.interval']
['L1-dcache-stores', 'spark.cleaner.referenceTracking']
['L1-dcache-stores', 'spark.cleaner.referenceTracking.blocking']
['L1-dcache-stores', 'spark.cleaner.referenceTracking.blocking.shuffle']
['L1-dcache-stores', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['L1-dcache-stores', 'spark.broadcast.checksum']
['L1-dcache-stores', 'spark.executor.heartbeatInterval']
['L1-dcache-stores', 'spark.files.fetchTimeout']
['L1-dcache-stores', 'spark.files.useFetchCache']
['L1-dcache-stores', 'spark.files.overwrite']
['L1-dcache-stores', 'spark.files.maxPartitionBytes']
['L1-dcache-stores', 'spark.files.openCostInBytes']
['L1-dcache-stores', 'spark.storage.memoryMapThreshold.1']
['L1-dcache-stores', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['L1-dcache-stores', 'spark.rpc.io.backLog']
['L1-dcache-stores', 'spark.port.maxRetries']
['L1-dcache-stores', 'spark.rpc.numRetries']
['L1-dcache-stores', 'spark.rpc.retry.wait']
['L1-dcache-stores', 'spark.rpc.lookupTimeout']
['L1-dcache-stores', 'spark.scheduler.minRegisteredResourcesRatio']
['L1-dcache-stores', 'spark.scheduler.mode']
['L1-dcache-stores', 'spark.scheduler.listenerbus.eventqueue.capacity']
['L1-dcache-stores', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['L1-dcache-stores', 'spark.task.reaper.enabled']
['L1-dcache-stores', 'spark.task.reaper.pollingInterval']
['L1-dcache-stores', 'spark.task.reaper.threadDump']
['L1-dcache-stores', 'spark.stage.maxConsecutiveAttempts']
['L1-dcache-stores', 'spark.streaming.backpressure.enabled']
['L1-dcache-stores', 'spark.streaming.blockInterval']
['L1-dcache-stores', 'spark.streaming.receiver.writeAheadLog.enable']
['L1-dcache-stores', 'spark.streaming.unpersist']
['L1-dcache-stores', 'spark.streaming.stopGracefullyOnShutdown']
['ld_blocks_partial.address_alias', 'spark.reducer.maxSizeInFlight']
['ld_blocks_partial.address_alias', 'spark.shuffle.file.buffer']
['ld_blocks_partial.address_alias', 'spark.shuffle.memoryFraction']
['ld_blocks_partial.address_alias', 'spark.shuffle.sort.bypassMergeThreshold']
['ld_blocks_partial.address_alias', 'spark.speculation.interval']
['ld_blocks_partial.address_alias', 'spark.speculation.multiplier']
['ld_blocks_partial.address_alias', 'spark.speculation.quantile']
['ld_blocks_partial.address_alias', 'spark.broadcast.blockSize']
['ld_blocks_partial.address_alias', 'spark.io.compression.codec']
['ld_blocks_partial.address_alias', 'spark.io.compression.lz4.blockSize']
['ld_blocks_partial.address_alias', 'spark.io.compression.snappy.blockSize']
['ld_blocks_partial.address_alias', 'spark.kryo.referenceTracking']
['ld_blocks_partial.address_alias', 'spark.kryoserializer.buffer.max']
['ld_blocks_partial.address_alias', 'spark.kryoserializer.buffer']
['ld_blocks_partial.address_alias', 'spark.driver.cores']
['ld_blocks_partial.address_alias', 'spark.executor.cores']
['ld_blocks_partial.address_alias', 'spark.driver.memory']
['ld_blocks_partial.address_alias', 'spark.executor.memory']
['ld_blocks_partial.address_alias', 'spark.storage.memoryFraction']
['ld_blocks_partial.address_alias', 'spark.storage.memoryMapThreshold']
['ld_blocks_partial.address_alias', 'spark.storage.unrollFraction']
['ld_blocks_partial.address_alias', 'spark.network.timeout']
['ld_blocks_partial.address_alias', 'spark.locality.wait']
['ld_blocks_partial.address_alias', 'spark.scheduler.revive.interval']
['ld_blocks_partial.address_alias', 'spark.task.maxFailures']
['ld_blocks_partial.address_alias', 'spark.shuffle.compress']
['ld_blocks_partial.address_alias', 'spark.memory.fraction']
['ld_blocks_partial.address_alias', 'spark.shuffle.spill.compress']
['ld_blocks_partial.address_alias', 'spark.speculation']
['ld_blocks_partial.address_alias', 'spark.broadcast.compress']
['ld_blocks_partial.address_alias', 'spark.rdd.compress']
['ld_blocks_partial.address_alias', 'spark.serializer']
['ld_blocks_partial.address_alias', 'spark.memory.storageFraction']
['ld_blocks_partial.address_alias', 'spark.default.parallelism']
['ld_blocks_partial.address_alias', 'spark.memory.offHeap.enabled']
['ld_blocks_partial.address_alias', 'spark.memory.offHeap.size']
['ld_blocks_partial.address_alias', 'spark.executor.instances']
['ld_blocks_partial.address_alias', 'spark.python.worker.memory']
['ld_blocks_partial.address_alias', 'spark.python.worker.reuse']
['ld_blocks_partial.address_alias', 'spark.rpc.message.maxSize']
['ld_blocks_partial.address_alias', 'spark.driver.maxResultSize']
['ld_blocks_partial.address_alias', 'spark.driver.memoryOverhead']
['ld_blocks_partial.address_alias', 'spark.reducer.maxReqsInFlight']
['ld_blocks_partial.address_alias', 'spark.reducer.maxBlocksInFlightPerAddress']
['ld_blocks_partial.address_alias', 'spark.maxRemoteBlockSizeFetchToMem']
['ld_blocks_partial.address_alias', 'spark.shuffle.io.maxRetries']
['ld_blocks_partial.address_alias', 'spark.shuffle.io.numConnectionsPerPeer']
['ld_blocks_partial.address_alias', 'spark.shuffle.io.preferDirectBufs']
['ld_blocks_partial.address_alias', 'spark.shuffle.io.backLog']
['ld_blocks_partial.address_alias', 'spark.shuffle.service.index.cache.size']
['ld_blocks_partial.address_alias', 'spark.shuffle.maxChunksBeingTransferred']
['ld_blocks_partial.address_alias', 'spark.serializer.objectStreamReset']
['ld_blocks_partial.address_alias', 'spark.memory.useLegacyMode']
['ld_blocks_partial.address_alias', 'spark.storage.replication.proactive']
['ld_blocks_partial.address_alias', 'spark.cleaner.periodicGC.interval']
['ld_blocks_partial.address_alias', 'spark.cleaner.referenceTracking']
['ld_blocks_partial.address_alias', 'spark.cleaner.referenceTracking.blocking']
['ld_blocks_partial.address_alias', 'spark.cleaner.referenceTracking.blocking.shuffle']
['ld_blocks_partial.address_alias', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['ld_blocks_partial.address_alias', 'spark.broadcast.checksum']
['ld_blocks_partial.address_alias', 'spark.executor.heartbeatInterval']
['ld_blocks_partial.address_alias', 'spark.files.fetchTimeout']
['ld_blocks_partial.address_alias', 'spark.files.useFetchCache']
['ld_blocks_partial.address_alias', 'spark.files.overwrite']
['ld_blocks_partial.address_alias', 'spark.files.maxPartitionBytes']
['ld_blocks_partial.address_alias', 'spark.files.openCostInBytes']
['ld_blocks_partial.address_alias', 'spark.storage.memoryMapThreshold.1']
['ld_blocks_partial.address_alias', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['ld_blocks_partial.address_alias', 'spark.rpc.io.backLog']
['ld_blocks_partial.address_alias', 'spark.port.maxRetries']
['ld_blocks_partial.address_alias', 'spark.rpc.numRetries']
['ld_blocks_partial.address_alias', 'spark.rpc.retry.wait']
['ld_blocks_partial.address_alias', 'spark.rpc.lookupTimeout']
['ld_blocks_partial.address_alias', 'spark.scheduler.minRegisteredResourcesRatio']
['ld_blocks_partial.address_alias', 'spark.scheduler.mode']
['ld_blocks_partial.address_alias', 'spark.scheduler.listenerbus.eventqueue.capacity']
['ld_blocks_partial.address_alias', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['ld_blocks_partial.address_alias', 'spark.task.reaper.enabled']
['ld_blocks_partial.address_alias', 'spark.task.reaper.pollingInterval']
['ld_blocks_partial.address_alias', 'spark.task.reaper.threadDump']
['ld_blocks_partial.address_alias', 'spark.stage.maxConsecutiveAttempts']
['ld_blocks_partial.address_alias', 'spark.streaming.backpressure.enabled']
['ld_blocks_partial.address_alias', 'spark.streaming.blockInterval']
['ld_blocks_partial.address_alias', 'spark.streaming.receiver.writeAheadLog.enable']
['ld_blocks_partial.address_alias', 'spark.streaming.unpersist']
['ld_blocks_partial.address_alias', 'spark.streaming.stopGracefullyOnShutdown']
['container_spec_cpu_shares', 'spark.reducer.maxSizeInFlight']
['container_spec_cpu_shares', 'spark.shuffle.file.buffer']
['container_spec_cpu_shares', 'spark.shuffle.memoryFraction']
['container_spec_cpu_shares', 'spark.shuffle.sort.bypassMergeThreshold']
['container_spec_cpu_shares', 'spark.speculation.interval']
['container_spec_cpu_shares', 'spark.speculation.multiplier']
['container_spec_cpu_shares', 'spark.speculation.quantile']
['container_spec_cpu_shares', 'spark.broadcast.blockSize']
['container_spec_cpu_shares', 'spark.io.compression.codec']
['container_spec_cpu_shares', 'spark.io.compression.lz4.blockSize']
['container_spec_cpu_shares', 'spark.io.compression.snappy.blockSize']
['container_spec_cpu_shares', 'spark.kryo.referenceTracking']
['container_spec_cpu_shares', 'spark.kryoserializer.buffer.max']
['container_spec_cpu_shares', 'spark.kryoserializer.buffer']
['container_spec_cpu_shares', 'spark.driver.cores']
['container_spec_cpu_shares', 'spark.executor.cores']
['container_spec_cpu_shares', 'spark.driver.memory']
['container_spec_cpu_shares', 'spark.executor.memory']
['container_spec_cpu_shares', 'spark.storage.memoryFraction']
['container_spec_cpu_shares', 'spark.storage.memoryMapThreshold']
['container_spec_cpu_shares', 'spark.storage.unrollFraction']
['container_spec_cpu_shares', 'spark.network.timeout']
['container_spec_cpu_shares', 'spark.locality.wait']
['container_spec_cpu_shares', 'spark.scheduler.revive.interval']
['container_spec_cpu_shares', 'spark.task.maxFailures']
['container_spec_cpu_shares', 'spark.shuffle.compress']
['container_spec_cpu_shares', 'spark.memory.fraction']
['container_spec_cpu_shares', 'spark.shuffle.spill.compress']
['container_spec_cpu_shares', 'spark.speculation']
['container_spec_cpu_shares', 'spark.broadcast.compress']
['container_spec_cpu_shares', 'spark.rdd.compress']
['container_spec_cpu_shares', 'spark.serializer']
['container_spec_cpu_shares', 'spark.memory.storageFraction']
['container_spec_cpu_shares', 'spark.default.parallelism']
['container_spec_cpu_shares', 'spark.memory.offHeap.enabled']
['container_spec_cpu_shares', 'spark.memory.offHeap.size']
['container_spec_cpu_shares', 'spark.executor.instances']
['container_spec_cpu_shares', 'spark.python.worker.memory']
['container_spec_cpu_shares', 'spark.python.worker.reuse']
['container_spec_cpu_shares', 'spark.rpc.message.maxSize']
['container_spec_cpu_shares', 'spark.driver.maxResultSize']
['container_spec_cpu_shares', 'spark.driver.memoryOverhead']
['container_spec_cpu_shares', 'spark.reducer.maxReqsInFlight']
['container_spec_cpu_shares', 'spark.reducer.maxBlocksInFlightPerAddress']
['container_spec_cpu_shares', 'spark.maxRemoteBlockSizeFetchToMem']
['container_spec_cpu_shares', 'spark.shuffle.io.maxRetries']
['container_spec_cpu_shares', 'spark.shuffle.io.numConnectionsPerPeer']
['container_spec_cpu_shares', 'spark.shuffle.io.preferDirectBufs']
['container_spec_cpu_shares', 'spark.shuffle.io.backLog']
['container_spec_cpu_shares', 'spark.shuffle.service.index.cache.size']
['container_spec_cpu_shares', 'spark.shuffle.maxChunksBeingTransferred']
['container_spec_cpu_shares', 'spark.serializer.objectStreamReset']
['container_spec_cpu_shares', 'spark.memory.useLegacyMode']
['container_spec_cpu_shares', 'spark.storage.replication.proactive']
['container_spec_cpu_shares', 'spark.cleaner.periodicGC.interval']
['container_spec_cpu_shares', 'spark.cleaner.referenceTracking']
['container_spec_cpu_shares', 'spark.cleaner.referenceTracking.blocking']
['container_spec_cpu_shares', 'spark.cleaner.referenceTracking.blocking.shuffle']
['container_spec_cpu_shares', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['container_spec_cpu_shares', 'spark.broadcast.checksum']
['container_spec_cpu_shares', 'spark.executor.heartbeatInterval']
['container_spec_cpu_shares', 'spark.files.fetchTimeout']
['container_spec_cpu_shares', 'spark.files.useFetchCache']
['container_spec_cpu_shares', 'spark.files.overwrite']
['container_spec_cpu_shares', 'spark.files.maxPartitionBytes']
['container_spec_cpu_shares', 'spark.files.openCostInBytes']
['container_spec_cpu_shares', 'spark.storage.memoryMapThreshold.1']
['container_spec_cpu_shares', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['container_spec_cpu_shares', 'spark.rpc.io.backLog']
['container_spec_cpu_shares', 'spark.port.maxRetries']
['container_spec_cpu_shares', 'spark.rpc.numRetries']
['container_spec_cpu_shares', 'spark.rpc.retry.wait']
['container_spec_cpu_shares', 'spark.rpc.lookupTimeout']
['container_spec_cpu_shares', 'spark.scheduler.minRegisteredResourcesRatio']
['container_spec_cpu_shares', 'spark.scheduler.mode']
['container_spec_cpu_shares', 'spark.scheduler.listenerbus.eventqueue.capacity']
['container_spec_cpu_shares', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['container_spec_cpu_shares', 'spark.task.reaper.enabled']
['container_spec_cpu_shares', 'spark.task.reaper.pollingInterval']
['container_spec_cpu_shares', 'spark.task.reaper.threadDump']
['container_spec_cpu_shares', 'spark.stage.maxConsecutiveAttempts']
['container_spec_cpu_shares', 'spark.streaming.backpressure.enabled']
['container_spec_cpu_shares', 'spark.streaming.blockInterval']
['container_spec_cpu_shares', 'spark.streaming.receiver.writeAheadLog.enable']
['container_spec_cpu_shares', 'spark.streaming.unpersist']
['container_spec_cpu_shares', 'spark.streaming.stopGracefullyOnShutdown']
['int_misc.recovery_cycles', 'spark.reducer.maxSizeInFlight']
['int_misc.recovery_cycles', 'spark.shuffle.file.buffer']
['int_misc.recovery_cycles', 'spark.shuffle.memoryFraction']
['int_misc.recovery_cycles', 'spark.shuffle.sort.bypassMergeThreshold']
['int_misc.recovery_cycles', 'spark.speculation.interval']
['int_misc.recovery_cycles', 'spark.speculation.multiplier']
['int_misc.recovery_cycles', 'spark.speculation.quantile']
['int_misc.recovery_cycles', 'spark.broadcast.blockSize']
['int_misc.recovery_cycles', 'spark.io.compression.codec']
['int_misc.recovery_cycles', 'spark.io.compression.lz4.blockSize']
['int_misc.recovery_cycles', 'spark.io.compression.snappy.blockSize']
['int_misc.recovery_cycles', 'spark.kryo.referenceTracking']
['int_misc.recovery_cycles', 'spark.kryoserializer.buffer.max']
['int_misc.recovery_cycles', 'spark.kryoserializer.buffer']
['int_misc.recovery_cycles', 'spark.driver.cores']
['int_misc.recovery_cycles', 'spark.executor.cores']
['int_misc.recovery_cycles', 'spark.driver.memory']
['int_misc.recovery_cycles', 'spark.executor.memory']
['int_misc.recovery_cycles', 'spark.storage.memoryFraction']
['int_misc.recovery_cycles', 'spark.storage.memoryMapThreshold']
['int_misc.recovery_cycles', 'spark.storage.unrollFraction']
['int_misc.recovery_cycles', 'spark.network.timeout']
['int_misc.recovery_cycles', 'spark.locality.wait']
['int_misc.recovery_cycles', 'spark.scheduler.revive.interval']
['int_misc.recovery_cycles', 'spark.task.maxFailures']
['int_misc.recovery_cycles', 'spark.shuffle.compress']
['int_misc.recovery_cycles', 'spark.memory.fraction']
['int_misc.recovery_cycles', 'spark.shuffle.spill.compress']
['int_misc.recovery_cycles', 'spark.speculation']
['int_misc.recovery_cycles', 'spark.broadcast.compress']
['int_misc.recovery_cycles', 'spark.rdd.compress']
['int_misc.recovery_cycles', 'spark.serializer']
['int_misc.recovery_cycles', 'spark.memory.storageFraction']
['int_misc.recovery_cycles', 'spark.default.parallelism']
['int_misc.recovery_cycles', 'spark.memory.offHeap.enabled']
['int_misc.recovery_cycles', 'spark.memory.offHeap.size']
['int_misc.recovery_cycles', 'spark.executor.instances']
['int_misc.recovery_cycles', 'spark.python.worker.memory']
['int_misc.recovery_cycles', 'spark.python.worker.reuse']
['int_misc.recovery_cycles', 'spark.rpc.message.maxSize']
['int_misc.recovery_cycles', 'spark.driver.maxResultSize']
['int_misc.recovery_cycles', 'spark.driver.memoryOverhead']
['int_misc.recovery_cycles', 'spark.reducer.maxReqsInFlight']
['int_misc.recovery_cycles', 'spark.reducer.maxBlocksInFlightPerAddress']
['int_misc.recovery_cycles', 'spark.maxRemoteBlockSizeFetchToMem']
['int_misc.recovery_cycles', 'spark.shuffle.io.maxRetries']
['int_misc.recovery_cycles', 'spark.shuffle.io.numConnectionsPerPeer']
['int_misc.recovery_cycles', 'spark.shuffle.io.preferDirectBufs']
['int_misc.recovery_cycles', 'spark.shuffle.io.backLog']
['int_misc.recovery_cycles', 'spark.shuffle.service.index.cache.size']
['int_misc.recovery_cycles', 'spark.shuffle.maxChunksBeingTransferred']
['int_misc.recovery_cycles', 'spark.serializer.objectStreamReset']
['int_misc.recovery_cycles', 'spark.memory.useLegacyMode']
['int_misc.recovery_cycles', 'spark.storage.replication.proactive']
['int_misc.recovery_cycles', 'spark.cleaner.periodicGC.interval']
['int_misc.recovery_cycles', 'spark.cleaner.referenceTracking']
['int_misc.recovery_cycles', 'spark.cleaner.referenceTracking.blocking']
['int_misc.recovery_cycles', 'spark.cleaner.referenceTracking.blocking.shuffle']
['int_misc.recovery_cycles', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['int_misc.recovery_cycles', 'spark.broadcast.checksum']
['int_misc.recovery_cycles', 'spark.executor.heartbeatInterval']
['int_misc.recovery_cycles', 'spark.files.fetchTimeout']
['int_misc.recovery_cycles', 'spark.files.useFetchCache']
['int_misc.recovery_cycles', 'spark.files.overwrite']
['int_misc.recovery_cycles', 'spark.files.maxPartitionBytes']
['int_misc.recovery_cycles', 'spark.files.openCostInBytes']
['int_misc.recovery_cycles', 'spark.storage.memoryMapThreshold.1']
['int_misc.recovery_cycles', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['int_misc.recovery_cycles', 'spark.rpc.io.backLog']
['int_misc.recovery_cycles', 'spark.port.maxRetries']
['int_misc.recovery_cycles', 'spark.rpc.numRetries']
['int_misc.recovery_cycles', 'spark.rpc.retry.wait']
['int_misc.recovery_cycles', 'spark.rpc.lookupTimeout']
['int_misc.recovery_cycles', 'spark.scheduler.minRegisteredResourcesRatio']
['int_misc.recovery_cycles', 'spark.scheduler.mode']
['int_misc.recovery_cycles', 'spark.scheduler.listenerbus.eventqueue.capacity']
['int_misc.recovery_cycles', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['int_misc.recovery_cycles', 'spark.task.reaper.enabled']
['int_misc.recovery_cycles', 'spark.task.reaper.pollingInterval']
['int_misc.recovery_cycles', 'spark.task.reaper.threadDump']
['int_misc.recovery_cycles', 'spark.stage.maxConsecutiveAttempts']
['int_misc.recovery_cycles', 'spark.streaming.backpressure.enabled']
['int_misc.recovery_cycles', 'spark.streaming.blockInterval']
['int_misc.recovery_cycles', 'spark.streaming.receiver.writeAheadLog.enable']
['int_misc.recovery_cycles', 'spark.streaming.unpersist']
['int_misc.recovery_cycles', 'spark.streaming.stopGracefullyOnShutdown']
['iTLB-load-misses', 'spark.reducer.maxSizeInFlight']
['iTLB-load-misses', 'spark.shuffle.file.buffer']
['iTLB-load-misses', 'spark.shuffle.memoryFraction']
['iTLB-load-misses', 'spark.shuffle.sort.bypassMergeThreshold']
['iTLB-load-misses', 'spark.speculation.interval']
['iTLB-load-misses', 'spark.speculation.multiplier']
['iTLB-load-misses', 'spark.speculation.quantile']
['iTLB-load-misses', 'spark.broadcast.blockSize']
['iTLB-load-misses', 'spark.io.compression.codec']
['iTLB-load-misses', 'spark.io.compression.lz4.blockSize']
['iTLB-load-misses', 'spark.io.compression.snappy.blockSize']
['iTLB-load-misses', 'spark.kryo.referenceTracking']
['iTLB-load-misses', 'spark.kryoserializer.buffer.max']
['iTLB-load-misses', 'spark.kryoserializer.buffer']
['iTLB-load-misses', 'spark.driver.cores']
['iTLB-load-misses', 'spark.executor.cores']
['iTLB-load-misses', 'spark.driver.memory']
['iTLB-load-misses', 'spark.executor.memory']
['iTLB-load-misses', 'spark.storage.memoryFraction']
['iTLB-load-misses', 'spark.storage.memoryMapThreshold']
['iTLB-load-misses', 'spark.storage.unrollFraction']
['iTLB-load-misses', 'spark.network.timeout']
['iTLB-load-misses', 'spark.locality.wait']
['iTLB-load-misses', 'spark.scheduler.revive.interval']
['iTLB-load-misses', 'spark.task.maxFailures']
['iTLB-load-misses', 'spark.shuffle.compress']
['iTLB-load-misses', 'spark.memory.fraction']
['iTLB-load-misses', 'spark.shuffle.spill.compress']
['iTLB-load-misses', 'spark.speculation']
['iTLB-load-misses', 'spark.broadcast.compress']
['iTLB-load-misses', 'spark.rdd.compress']
['iTLB-load-misses', 'spark.serializer']
['iTLB-load-misses', 'spark.memory.storageFraction']
['iTLB-load-misses', 'spark.default.parallelism']
['iTLB-load-misses', 'spark.memory.offHeap.enabled']
['iTLB-load-misses', 'spark.memory.offHeap.size']
['iTLB-load-misses', 'spark.executor.instances']
['iTLB-load-misses', 'spark.python.worker.memory']
['iTLB-load-misses', 'spark.python.worker.reuse']
['iTLB-load-misses', 'spark.rpc.message.maxSize']
['iTLB-load-misses', 'spark.driver.maxResultSize']
['iTLB-load-misses', 'spark.driver.memoryOverhead']
['iTLB-load-misses', 'spark.reducer.maxReqsInFlight']
['iTLB-load-misses', 'spark.reducer.maxBlocksInFlightPerAddress']
['iTLB-load-misses', 'spark.maxRemoteBlockSizeFetchToMem']
['iTLB-load-misses', 'spark.shuffle.io.maxRetries']
['iTLB-load-misses', 'spark.shuffle.io.numConnectionsPerPeer']
['iTLB-load-misses', 'spark.shuffle.io.preferDirectBufs']
['iTLB-load-misses', 'spark.shuffle.io.backLog']
['iTLB-load-misses', 'spark.shuffle.service.index.cache.size']
['iTLB-load-misses', 'spark.shuffle.maxChunksBeingTransferred']
['iTLB-load-misses', 'spark.serializer.objectStreamReset']
['iTLB-load-misses', 'spark.memory.useLegacyMode']
['iTLB-load-misses', 'spark.storage.replication.proactive']
['iTLB-load-misses', 'spark.cleaner.periodicGC.interval']
['iTLB-load-misses', 'spark.cleaner.referenceTracking']
['iTLB-load-misses', 'spark.cleaner.referenceTracking.blocking']
['iTLB-load-misses', 'spark.cleaner.referenceTracking.blocking.shuffle']
['iTLB-load-misses', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['iTLB-load-misses', 'spark.broadcast.checksum']
['iTLB-load-misses', 'spark.executor.heartbeatInterval']
['iTLB-load-misses', 'spark.files.fetchTimeout']
['iTLB-load-misses', 'spark.files.useFetchCache']
['iTLB-load-misses', 'spark.files.overwrite']
['iTLB-load-misses', 'spark.files.maxPartitionBytes']
['iTLB-load-misses', 'spark.files.openCostInBytes']
['iTLB-load-misses', 'spark.storage.memoryMapThreshold.1']
['iTLB-load-misses', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['iTLB-load-misses', 'spark.rpc.io.backLog']
['iTLB-load-misses', 'spark.port.maxRetries']
['iTLB-load-misses', 'spark.rpc.numRetries']
['iTLB-load-misses', 'spark.rpc.retry.wait']
['iTLB-load-misses', 'spark.rpc.lookupTimeout']
['iTLB-load-misses', 'spark.scheduler.minRegisteredResourcesRatio']
['iTLB-load-misses', 'spark.scheduler.mode']
['iTLB-load-misses', 'spark.scheduler.listenerbus.eventqueue.capacity']
['iTLB-load-misses', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['iTLB-load-misses', 'spark.task.reaper.enabled']
['iTLB-load-misses', 'spark.task.reaper.pollingInterval']
['iTLB-load-misses', 'spark.task.reaper.threadDump']
['iTLB-load-misses', 'spark.stage.maxConsecutiveAttempts']
['iTLB-load-misses', 'spark.streaming.backpressure.enabled']
['iTLB-load-misses', 'spark.streaming.blockInterval']
['iTLB-load-misses', 'spark.streaming.receiver.writeAheadLog.enable']
['iTLB-load-misses', 'spark.streaming.unpersist']
['iTLB-load-misses', 'spark.streaming.stopGracefullyOnShutdown']
['node-store-misses', 'spark.reducer.maxSizeInFlight']
['node-store-misses', 'spark.shuffle.file.buffer']
['node-store-misses', 'spark.shuffle.memoryFraction']
['node-store-misses', 'spark.shuffle.sort.bypassMergeThreshold']
['node-store-misses', 'spark.speculation.interval']
['node-store-misses', 'spark.speculation.multiplier']
['node-store-misses', 'spark.speculation.quantile']
['node-store-misses', 'spark.broadcast.blockSize']
['node-store-misses', 'spark.io.compression.codec']
['node-store-misses', 'spark.io.compression.lz4.blockSize']
['node-store-misses', 'spark.io.compression.snappy.blockSize']
['node-store-misses', 'spark.kryo.referenceTracking']
['node-store-misses', 'spark.kryoserializer.buffer.max']
['node-store-misses', 'spark.kryoserializer.buffer']
['node-store-misses', 'spark.driver.cores']
['node-store-misses', 'spark.executor.cores']
['node-store-misses', 'spark.driver.memory']
['node-store-misses', 'spark.executor.memory']
['node-store-misses', 'spark.storage.memoryFraction']
['node-store-misses', 'spark.storage.memoryMapThreshold']
['node-store-misses', 'spark.storage.unrollFraction']
['node-store-misses', 'spark.network.timeout']
['node-store-misses', 'spark.locality.wait']
['node-store-misses', 'spark.scheduler.revive.interval']
['node-store-misses', 'spark.task.maxFailures']
['node-store-misses', 'spark.shuffle.compress']
['node-store-misses', 'spark.memory.fraction']
['node-store-misses', 'spark.shuffle.spill.compress']
['node-store-misses', 'spark.speculation']
['node-store-misses', 'spark.broadcast.compress']
['node-store-misses', 'spark.rdd.compress']
['node-store-misses', 'spark.serializer']
['node-store-misses', 'spark.memory.storageFraction']
['node-store-misses', 'spark.default.parallelism']
['node-store-misses', 'spark.memory.offHeap.enabled']
['node-store-misses', 'spark.memory.offHeap.size']
['node-store-misses', 'spark.executor.instances']
['node-store-misses', 'spark.python.worker.memory']
['node-store-misses', 'spark.python.worker.reuse']
['node-store-misses', 'spark.rpc.message.maxSize']
['node-store-misses', 'spark.driver.maxResultSize']
['node-store-misses', 'spark.driver.memoryOverhead']
['node-store-misses', 'spark.reducer.maxReqsInFlight']
['node-store-misses', 'spark.reducer.maxBlocksInFlightPerAddress']
['node-store-misses', 'spark.maxRemoteBlockSizeFetchToMem']
['node-store-misses', 'spark.shuffle.io.maxRetries']
['node-store-misses', 'spark.shuffle.io.numConnectionsPerPeer']
['node-store-misses', 'spark.shuffle.io.preferDirectBufs']
['node-store-misses', 'spark.shuffle.io.backLog']
['node-store-misses', 'spark.shuffle.service.index.cache.size']
['node-store-misses', 'spark.shuffle.maxChunksBeingTransferred']
['node-store-misses', 'spark.serializer.objectStreamReset']
['node-store-misses', 'spark.memory.useLegacyMode']
['node-store-misses', 'spark.storage.replication.proactive']
['node-store-misses', 'spark.cleaner.periodicGC.interval']
['node-store-misses', 'spark.cleaner.referenceTracking']
['node-store-misses', 'spark.cleaner.referenceTracking.blocking']
['node-store-misses', 'spark.cleaner.referenceTracking.blocking.shuffle']
['node-store-misses', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['node-store-misses', 'spark.broadcast.checksum']
['node-store-misses', 'spark.executor.heartbeatInterval']
['node-store-misses', 'spark.files.fetchTimeout']
['node-store-misses', 'spark.files.useFetchCache']
['node-store-misses', 'spark.files.overwrite']
['node-store-misses', 'spark.files.maxPartitionBytes']
['node-store-misses', 'spark.files.openCostInBytes']
['node-store-misses', 'spark.storage.memoryMapThreshold.1']
['node-store-misses', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['node-store-misses', 'spark.rpc.io.backLog']
['node-store-misses', 'spark.port.maxRetries']
['node-store-misses', 'spark.rpc.numRetries']
['node-store-misses', 'spark.rpc.retry.wait']
['node-store-misses', 'spark.rpc.lookupTimeout']
['node-store-misses', 'spark.scheduler.minRegisteredResourcesRatio']
['node-store-misses', 'spark.scheduler.mode']
['node-store-misses', 'spark.scheduler.listenerbus.eventqueue.capacity']
['node-store-misses', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['node-store-misses', 'spark.task.reaper.enabled']
['node-store-misses', 'spark.task.reaper.pollingInterval']
['node-store-misses', 'spark.task.reaper.threadDump']
['node-store-misses', 'spark.stage.maxConsecutiveAttempts']
['node-store-misses', 'spark.streaming.backpressure.enabled']
['node-store-misses', 'spark.streaming.blockInterval']
['node-store-misses', 'spark.streaming.receiver.writeAheadLog.enable']
['node-store-misses', 'spark.streaming.unpersist']
['node-store-misses', 'spark.streaming.stopGracefullyOnShutdown']
['unix sockets - str', 'spark.reducer.maxSizeInFlight']
['unix sockets - str', 'spark.shuffle.file.buffer']
['unix sockets - str', 'spark.shuffle.memoryFraction']
['unix sockets - str', 'spark.shuffle.sort.bypassMergeThreshold']
['unix sockets - str', 'spark.speculation.interval']
['unix sockets - str', 'spark.speculation.multiplier']
['unix sockets - str', 'spark.speculation.quantile']
['unix sockets - str', 'spark.broadcast.blockSize']
['unix sockets - str', 'spark.io.compression.codec']
['unix sockets - str', 'spark.io.compression.lz4.blockSize']
['unix sockets - str', 'spark.io.compression.snappy.blockSize']
['unix sockets - str', 'spark.kryo.referenceTracking']
['unix sockets - str', 'spark.kryoserializer.buffer.max']
['unix sockets - str', 'spark.kryoserializer.buffer']
['unix sockets - str', 'spark.driver.cores']
['unix sockets - str', 'spark.executor.cores']
['unix sockets - str', 'spark.driver.memory']
['unix sockets - str', 'spark.executor.memory']
['unix sockets - str', 'spark.storage.memoryFraction']
['unix sockets - str', 'spark.storage.memoryMapThreshold']
['unix sockets - str', 'spark.storage.unrollFraction']
['unix sockets - str', 'spark.network.timeout']
['unix sockets - str', 'spark.locality.wait']
['unix sockets - str', 'spark.scheduler.revive.interval']
['unix sockets - str', 'spark.task.maxFailures']
['unix sockets - str', 'spark.shuffle.compress']
['unix sockets - str', 'spark.memory.fraction']
['unix sockets - str', 'spark.shuffle.spill.compress']
['unix sockets - str', 'spark.speculation']
['unix sockets - str', 'spark.broadcast.compress']
['unix sockets - str', 'spark.rdd.compress']
['unix sockets - str', 'spark.serializer']
['unix sockets - str', 'spark.memory.storageFraction']
['unix sockets - str', 'spark.default.parallelism']
['unix sockets - str', 'spark.memory.offHeap.enabled']
['unix sockets - str', 'spark.memory.offHeap.size']
['unix sockets - str', 'spark.executor.instances']
['unix sockets - str', 'spark.python.worker.memory']
['unix sockets - str', 'spark.python.worker.reuse']
['unix sockets - str', 'spark.rpc.message.maxSize']
['unix sockets - str', 'spark.driver.maxResultSize']
['unix sockets - str', 'spark.driver.memoryOverhead']
['unix sockets - str', 'spark.reducer.maxReqsInFlight']
['unix sockets - str', 'spark.reducer.maxBlocksInFlightPerAddress']
['unix sockets - str', 'spark.maxRemoteBlockSizeFetchToMem']
['unix sockets - str', 'spark.shuffle.io.maxRetries']
['unix sockets - str', 'spark.shuffle.io.numConnectionsPerPeer']
['unix sockets - str', 'spark.shuffle.io.preferDirectBufs']
['unix sockets - str', 'spark.shuffle.io.backLog']
['unix sockets - str', 'spark.shuffle.service.index.cache.size']
['unix sockets - str', 'spark.shuffle.maxChunksBeingTransferred']
['unix sockets - str', 'spark.serializer.objectStreamReset']
['unix sockets - str', 'spark.memory.useLegacyMode']
['unix sockets - str', 'spark.storage.replication.proactive']
['unix sockets - str', 'spark.cleaner.periodicGC.interval']
['unix sockets - str', 'spark.cleaner.referenceTracking']
['unix sockets - str', 'spark.cleaner.referenceTracking.blocking']
['unix sockets - str', 'spark.cleaner.referenceTracking.blocking.shuffle']
['unix sockets - str', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['unix sockets - str', 'spark.broadcast.checksum']
['unix sockets - str', 'spark.executor.heartbeatInterval']
['unix sockets - str', 'spark.files.fetchTimeout']
['unix sockets - str', 'spark.files.useFetchCache']
['unix sockets - str', 'spark.files.overwrite']
['unix sockets - str', 'spark.files.maxPartitionBytes']
['unix sockets - str', 'spark.files.openCostInBytes']
['unix sockets - str', 'spark.storage.memoryMapThreshold.1']
['unix sockets - str', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['unix sockets - str', 'spark.rpc.io.backLog']
['unix sockets - str', 'spark.port.maxRetries']
['unix sockets - str', 'spark.rpc.numRetries']
['unix sockets - str', 'spark.rpc.retry.wait']
['unix sockets - str', 'spark.rpc.lookupTimeout']
['unix sockets - str', 'spark.scheduler.minRegisteredResourcesRatio']
['unix sockets - str', 'spark.scheduler.mode']
['unix sockets - str', 'spark.scheduler.listenerbus.eventqueue.capacity']
['unix sockets - str', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['unix sockets - str', 'spark.task.reaper.enabled']
['unix sockets - str', 'spark.task.reaper.pollingInterval']
['unix sockets - str', 'spark.task.reaper.threadDump']
['unix sockets - str', 'spark.stage.maxConsecutiveAttempts']
['unix sockets - str', 'spark.streaming.backpressure.enabled']
['unix sockets - str', 'spark.streaming.blockInterval']
['unix sockets - str', 'spark.streaming.receiver.writeAheadLog.enable']
['unix sockets - str', 'spark.streaming.unpersist']
['unix sockets - str', 'spark.streaming.stopGracefullyOnShutdown']
['topdown-total-slots', 'spark.reducer.maxSizeInFlight']
['topdown-total-slots', 'spark.shuffle.file.buffer']
['topdown-total-slots', 'spark.shuffle.memoryFraction']
['topdown-total-slots', 'spark.shuffle.sort.bypassMergeThreshold']
['topdown-total-slots', 'spark.speculation.interval']
['topdown-total-slots', 'spark.speculation.multiplier']
['topdown-total-slots', 'spark.speculation.quantile']
['topdown-total-slots', 'spark.broadcast.blockSize']
['topdown-total-slots', 'spark.io.compression.codec']
['topdown-total-slots', 'spark.io.compression.lz4.blockSize']
['topdown-total-slots', 'spark.io.compression.snappy.blockSize']
['topdown-total-slots', 'spark.kryo.referenceTracking']
['topdown-total-slots', 'spark.kryoserializer.buffer.max']
['topdown-total-slots', 'spark.kryoserializer.buffer']
['topdown-total-slots', 'spark.driver.cores']
['topdown-total-slots', 'spark.executor.cores']
['topdown-total-slots', 'spark.driver.memory']
['topdown-total-slots', 'spark.executor.memory']
['topdown-total-slots', 'spark.storage.memoryFraction']
['topdown-total-slots', 'spark.storage.memoryMapThreshold']
['topdown-total-slots', 'spark.storage.unrollFraction']
['topdown-total-slots', 'spark.network.timeout']
['topdown-total-slots', 'spark.locality.wait']
['topdown-total-slots', 'spark.scheduler.revive.interval']
['topdown-total-slots', 'spark.task.maxFailures']
['topdown-total-slots', 'spark.shuffle.compress']
['topdown-total-slots', 'spark.memory.fraction']
['topdown-total-slots', 'spark.shuffle.spill.compress']
['topdown-total-slots', 'spark.speculation']
['topdown-total-slots', 'spark.broadcast.compress']
['topdown-total-slots', 'spark.rdd.compress']
['topdown-total-slots', 'spark.serializer']
['topdown-total-slots', 'spark.memory.storageFraction']
['topdown-total-slots', 'spark.default.parallelism']
['topdown-total-slots', 'spark.memory.offHeap.enabled']
['topdown-total-slots', 'spark.memory.offHeap.size']
['topdown-total-slots', 'spark.executor.instances']
['topdown-total-slots', 'spark.python.worker.memory']
['topdown-total-slots', 'spark.python.worker.reuse']
['topdown-total-slots', 'spark.rpc.message.maxSize']
['topdown-total-slots', 'spark.driver.maxResultSize']
['topdown-total-slots', 'spark.driver.memoryOverhead']
['topdown-total-slots', 'spark.reducer.maxReqsInFlight']
['topdown-total-slots', 'spark.reducer.maxBlocksInFlightPerAddress']
['topdown-total-slots', 'spark.maxRemoteBlockSizeFetchToMem']
['topdown-total-slots', 'spark.shuffle.io.maxRetries']
['topdown-total-slots', 'spark.shuffle.io.numConnectionsPerPeer']
['topdown-total-slots', 'spark.shuffle.io.preferDirectBufs']
['topdown-total-slots', 'spark.shuffle.io.backLog']
['topdown-total-slots', 'spark.shuffle.service.index.cache.size']
['topdown-total-slots', 'spark.shuffle.maxChunksBeingTransferred']
['topdown-total-slots', 'spark.serializer.objectStreamReset']
['topdown-total-slots', 'spark.memory.useLegacyMode']
['topdown-total-slots', 'spark.storage.replication.proactive']
['topdown-total-slots', 'spark.cleaner.periodicGC.interval']
['topdown-total-slots', 'spark.cleaner.referenceTracking']
['topdown-total-slots', 'spark.cleaner.referenceTracking.blocking']
['topdown-total-slots', 'spark.cleaner.referenceTracking.blocking.shuffle']
['topdown-total-slots', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['topdown-total-slots', 'spark.broadcast.checksum']
['topdown-total-slots', 'spark.executor.heartbeatInterval']
['topdown-total-slots', 'spark.files.fetchTimeout']
['topdown-total-slots', 'spark.files.useFetchCache']
['topdown-total-slots', 'spark.files.overwrite']
['topdown-total-slots', 'spark.files.maxPartitionBytes']
['topdown-total-slots', 'spark.files.openCostInBytes']
['topdown-total-slots', 'spark.storage.memoryMapThreshold.1']
['topdown-total-slots', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['topdown-total-slots', 'spark.rpc.io.backLog']
['topdown-total-slots', 'spark.port.maxRetries']
['topdown-total-slots', 'spark.rpc.numRetries']
['topdown-total-slots', 'spark.rpc.retry.wait']
['topdown-total-slots', 'spark.rpc.lookupTimeout']
['topdown-total-slots', 'spark.scheduler.minRegisteredResourcesRatio']
['topdown-total-slots', 'spark.scheduler.mode']
['topdown-total-slots', 'spark.scheduler.listenerbus.eventqueue.capacity']
['topdown-total-slots', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['topdown-total-slots', 'spark.task.reaper.enabled']
['topdown-total-slots', 'spark.task.reaper.pollingInterval']
['topdown-total-slots', 'spark.task.reaper.threadDump']
['topdown-total-slots', 'spark.stage.maxConsecutiveAttempts']
['topdown-total-slots', 'spark.streaming.backpressure.enabled']
['topdown-total-slots', 'spark.streaming.blockInterval']
['topdown-total-slots', 'spark.streaming.receiver.writeAheadLog.enable']
['topdown-total-slots', 'spark.streaming.unpersist']
['topdown-total-slots', 'spark.streaming.stopGracefullyOnShutdown']
['container_start_time_seconds', 'spark.reducer.maxSizeInFlight']
['container_start_time_seconds', 'spark.shuffle.file.buffer']
['container_start_time_seconds', 'spark.shuffle.memoryFraction']
['container_start_time_seconds', 'spark.shuffle.sort.bypassMergeThreshold']
['container_start_time_seconds', 'spark.speculation.interval']
['container_start_time_seconds', 'spark.speculation.multiplier']
['container_start_time_seconds', 'spark.speculation.quantile']
['container_start_time_seconds', 'spark.broadcast.blockSize']
['container_start_time_seconds', 'spark.io.compression.codec']
['container_start_time_seconds', 'spark.io.compression.lz4.blockSize']
['container_start_time_seconds', 'spark.io.compression.snappy.blockSize']
['container_start_time_seconds', 'spark.kryo.referenceTracking']
['container_start_time_seconds', 'spark.kryoserializer.buffer.max']
['container_start_time_seconds', 'spark.kryoserializer.buffer']
['container_start_time_seconds', 'spark.driver.cores']
['container_start_time_seconds', 'spark.executor.cores']
['container_start_time_seconds', 'spark.driver.memory']
['container_start_time_seconds', 'spark.executor.memory']
['container_start_time_seconds', 'spark.storage.memoryFraction']
['container_start_time_seconds', 'spark.storage.memoryMapThreshold']
['container_start_time_seconds', 'spark.storage.unrollFraction']
['container_start_time_seconds', 'spark.network.timeout']
['container_start_time_seconds', 'spark.locality.wait']
['container_start_time_seconds', 'spark.scheduler.revive.interval']
['container_start_time_seconds', 'spark.task.maxFailures']
['container_start_time_seconds', 'spark.shuffle.compress']
['container_start_time_seconds', 'spark.memory.fraction']
['container_start_time_seconds', 'spark.shuffle.spill.compress']
['container_start_time_seconds', 'spark.speculation']
['container_start_time_seconds', 'spark.broadcast.compress']
['container_start_time_seconds', 'spark.rdd.compress']
['container_start_time_seconds', 'spark.serializer']
['container_start_time_seconds', 'spark.memory.storageFraction']
['container_start_time_seconds', 'spark.default.parallelism']
['container_start_time_seconds', 'spark.memory.offHeap.enabled']
['container_start_time_seconds', 'spark.memory.offHeap.size']
['container_start_time_seconds', 'spark.executor.instances']
['container_start_time_seconds', 'spark.python.worker.memory']
['container_start_time_seconds', 'spark.python.worker.reuse']
['container_start_time_seconds', 'spark.rpc.message.maxSize']
['container_start_time_seconds', 'spark.driver.maxResultSize']
['container_start_time_seconds', 'spark.driver.memoryOverhead']
['container_start_time_seconds', 'spark.reducer.maxReqsInFlight']
['container_start_time_seconds', 'spark.reducer.maxBlocksInFlightPerAddress']
['container_start_time_seconds', 'spark.maxRemoteBlockSizeFetchToMem']
['container_start_time_seconds', 'spark.shuffle.io.maxRetries']
['container_start_time_seconds', 'spark.shuffle.io.numConnectionsPerPeer']
['container_start_time_seconds', 'spark.shuffle.io.preferDirectBufs']
['container_start_time_seconds', 'spark.shuffle.io.backLog']
['container_start_time_seconds', 'spark.shuffle.service.index.cache.size']
['container_start_time_seconds', 'spark.shuffle.maxChunksBeingTransferred']
['container_start_time_seconds', 'spark.serializer.objectStreamReset']
['container_start_time_seconds', 'spark.memory.useLegacyMode']
['container_start_time_seconds', 'spark.storage.replication.proactive']
['container_start_time_seconds', 'spark.cleaner.periodicGC.interval']
['container_start_time_seconds', 'spark.cleaner.referenceTracking']
['container_start_time_seconds', 'spark.cleaner.referenceTracking.blocking']
['container_start_time_seconds', 'spark.cleaner.referenceTracking.blocking.shuffle']
['container_start_time_seconds', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['container_start_time_seconds', 'spark.broadcast.checksum']
['container_start_time_seconds', 'spark.executor.heartbeatInterval']
['container_start_time_seconds', 'spark.files.fetchTimeout']
['container_start_time_seconds', 'spark.files.useFetchCache']
['container_start_time_seconds', 'spark.files.overwrite']
['container_start_time_seconds', 'spark.files.maxPartitionBytes']
['container_start_time_seconds', 'spark.files.openCostInBytes']
['container_start_time_seconds', 'spark.storage.memoryMapThreshold.1']
['container_start_time_seconds', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['container_start_time_seconds', 'spark.rpc.io.backLog']
['container_start_time_seconds', 'spark.port.maxRetries']
['container_start_time_seconds', 'spark.rpc.numRetries']
['container_start_time_seconds', 'spark.rpc.retry.wait']
['container_start_time_seconds', 'spark.rpc.lookupTimeout']
['container_start_time_seconds', 'spark.scheduler.minRegisteredResourcesRatio']
['container_start_time_seconds', 'spark.scheduler.mode']
['container_start_time_seconds', 'spark.scheduler.listenerbus.eventqueue.capacity']
['container_start_time_seconds', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['container_start_time_seconds', 'spark.task.reaper.enabled']
['container_start_time_seconds', 'spark.task.reaper.pollingInterval']
['container_start_time_seconds', 'spark.task.reaper.threadDump']
['container_start_time_seconds', 'spark.stage.maxConsecutiveAttempts']
['container_start_time_seconds', 'spark.streaming.backpressure.enabled']
['container_start_time_seconds', 'spark.streaming.blockInterval']
['container_start_time_seconds', 'spark.streaming.receiver.writeAheadLog.enable']
['container_start_time_seconds', 'spark.streaming.unpersist']
['container_start_time_seconds', 'spark.streaming.stopGracefullyOnShutdown']
['total cpu usage - idl', 'spark.reducer.maxSizeInFlight']
['total cpu usage - idl', 'spark.shuffle.file.buffer']
['total cpu usage - idl', 'spark.shuffle.memoryFraction']
['total cpu usage - idl', 'spark.shuffle.sort.bypassMergeThreshold']
['total cpu usage - idl', 'spark.speculation.interval']
['total cpu usage - idl', 'spark.speculation.multiplier']
['total cpu usage - idl', 'spark.speculation.quantile']
['total cpu usage - idl', 'spark.broadcast.blockSize']
['total cpu usage - idl', 'spark.io.compression.codec']
['total cpu usage - idl', 'spark.io.compression.lz4.blockSize']
['total cpu usage - idl', 'spark.io.compression.snappy.blockSize']
['total cpu usage - idl', 'spark.kryo.referenceTracking']
['total cpu usage - idl', 'spark.kryoserializer.buffer.max']
['total cpu usage - idl', 'spark.kryoserializer.buffer']
['total cpu usage - idl', 'spark.driver.cores']
['total cpu usage - idl', 'spark.executor.cores']
['total cpu usage - idl', 'spark.driver.memory']
['total cpu usage - idl', 'spark.executor.memory']
['total cpu usage - idl', 'spark.storage.memoryFraction']
['total cpu usage - idl', 'spark.storage.memoryMapThreshold']
['total cpu usage - idl', 'spark.storage.unrollFraction']
['total cpu usage - idl', 'spark.network.timeout']
['total cpu usage - idl', 'spark.locality.wait']
['total cpu usage - idl', 'spark.scheduler.revive.interval']
['total cpu usage - idl', 'spark.task.maxFailures']
['total cpu usage - idl', 'spark.shuffle.compress']
['total cpu usage - idl', 'spark.memory.fraction']
['total cpu usage - idl', 'spark.shuffle.spill.compress']
['total cpu usage - idl', 'spark.speculation']
['total cpu usage - idl', 'spark.broadcast.compress']
['total cpu usage - idl', 'spark.rdd.compress']
['total cpu usage - idl', 'spark.serializer']
['total cpu usage - idl', 'spark.memory.storageFraction']
['total cpu usage - idl', 'spark.default.parallelism']
['total cpu usage - idl', 'spark.memory.offHeap.enabled']
['total cpu usage - idl', 'spark.memory.offHeap.size']
['total cpu usage - idl', 'spark.executor.instances']
['total cpu usage - idl', 'spark.python.worker.memory']
['total cpu usage - idl', 'spark.python.worker.reuse']
['total cpu usage - idl', 'spark.rpc.message.maxSize']
['total cpu usage - idl', 'spark.driver.maxResultSize']
['total cpu usage - idl', 'spark.driver.memoryOverhead']
['total cpu usage - idl', 'spark.reducer.maxReqsInFlight']
['total cpu usage - idl', 'spark.reducer.maxBlocksInFlightPerAddress']
['total cpu usage - idl', 'spark.maxRemoteBlockSizeFetchToMem']
['total cpu usage - idl', 'spark.shuffle.io.maxRetries']
['total cpu usage - idl', 'spark.shuffle.io.numConnectionsPerPeer']
['total cpu usage - idl', 'spark.shuffle.io.preferDirectBufs']
['total cpu usage - idl', 'spark.shuffle.io.backLog']
['total cpu usage - idl', 'spark.shuffle.service.index.cache.size']
['total cpu usage - idl', 'spark.shuffle.maxChunksBeingTransferred']
['total cpu usage - idl', 'spark.serializer.objectStreamReset']
['total cpu usage - idl', 'spark.memory.useLegacyMode']
['total cpu usage - idl', 'spark.storage.replication.proactive']
['total cpu usage - idl', 'spark.cleaner.periodicGC.interval']
['total cpu usage - idl', 'spark.cleaner.referenceTracking']
['total cpu usage - idl', 'spark.cleaner.referenceTracking.blocking']
['total cpu usage - idl', 'spark.cleaner.referenceTracking.blocking.shuffle']
['total cpu usage - idl', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['total cpu usage - idl', 'spark.broadcast.checksum']
['total cpu usage - idl', 'spark.executor.heartbeatInterval']
['total cpu usage - idl', 'spark.files.fetchTimeout']
['total cpu usage - idl', 'spark.files.useFetchCache']
['total cpu usage - idl', 'spark.files.overwrite']
['total cpu usage - idl', 'spark.files.maxPartitionBytes']
['total cpu usage - idl', 'spark.files.openCostInBytes']
['total cpu usage - idl', 'spark.storage.memoryMapThreshold.1']
['total cpu usage - idl', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['total cpu usage - idl', 'spark.rpc.io.backLog']
['total cpu usage - idl', 'spark.port.maxRetries']
['total cpu usage - idl', 'spark.rpc.numRetries']
['total cpu usage - idl', 'spark.rpc.retry.wait']
['total cpu usage - idl', 'spark.rpc.lookupTimeout']
['total cpu usage - idl', 'spark.scheduler.minRegisteredResourcesRatio']
['total cpu usage - idl', 'spark.scheduler.mode']
['total cpu usage - idl', 'spark.scheduler.listenerbus.eventqueue.capacity']
['total cpu usage - idl', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['total cpu usage - idl', 'spark.task.reaper.enabled']
['total cpu usage - idl', 'spark.task.reaper.pollingInterval']
['total cpu usage - idl', 'spark.task.reaper.threadDump']
['total cpu usage - idl', 'spark.stage.maxConsecutiveAttempts']
['total cpu usage - idl', 'spark.streaming.backpressure.enabled']
['total cpu usage - idl', 'spark.streaming.blockInterval']
['total cpu usage - idl', 'spark.streaming.receiver.writeAheadLog.enable']
['total cpu usage - idl', 'spark.streaming.unpersist']
['total cpu usage - idl', 'spark.streaming.stopGracefullyOnShutdown']
['container_cpu_system_seconds_total', 'spark.reducer.maxSizeInFlight']
['container_cpu_system_seconds_total', 'spark.shuffle.file.buffer']
['container_cpu_system_seconds_total', 'spark.shuffle.memoryFraction']
['container_cpu_system_seconds_total', 'spark.shuffle.sort.bypassMergeThreshold']
['container_cpu_system_seconds_total', 'spark.speculation.interval']
['container_cpu_system_seconds_total', 'spark.speculation.multiplier']
['container_cpu_system_seconds_total', 'spark.speculation.quantile']
['container_cpu_system_seconds_total', 'spark.broadcast.blockSize']
['container_cpu_system_seconds_total', 'spark.io.compression.codec']
['container_cpu_system_seconds_total', 'spark.io.compression.lz4.blockSize']
['container_cpu_system_seconds_total', 'spark.io.compression.snappy.blockSize']
['container_cpu_system_seconds_total', 'spark.kryo.referenceTracking']
['container_cpu_system_seconds_total', 'spark.kryoserializer.buffer.max']
['container_cpu_system_seconds_total', 'spark.kryoserializer.buffer']
['container_cpu_system_seconds_total', 'spark.driver.cores']
['container_cpu_system_seconds_total', 'spark.executor.cores']
['container_cpu_system_seconds_total', 'spark.driver.memory']
['container_cpu_system_seconds_total', 'spark.executor.memory']
['container_cpu_system_seconds_total', 'spark.storage.memoryFraction']
['container_cpu_system_seconds_total', 'spark.storage.memoryMapThreshold']
['container_cpu_system_seconds_total', 'spark.storage.unrollFraction']
['container_cpu_system_seconds_total', 'spark.network.timeout']
['container_cpu_system_seconds_total', 'spark.locality.wait']
['container_cpu_system_seconds_total', 'spark.scheduler.revive.interval']
['container_cpu_system_seconds_total', 'spark.task.maxFailures']
['container_cpu_system_seconds_total', 'spark.shuffle.compress']
['container_cpu_system_seconds_total', 'spark.memory.fraction']
['container_cpu_system_seconds_total', 'spark.shuffle.spill.compress']
['container_cpu_system_seconds_total', 'spark.speculation']
['container_cpu_system_seconds_total', 'spark.broadcast.compress']
['container_cpu_system_seconds_total', 'spark.rdd.compress']
['container_cpu_system_seconds_total', 'spark.serializer']
['container_cpu_system_seconds_total', 'spark.memory.storageFraction']
['container_cpu_system_seconds_total', 'spark.default.parallelism']
['container_cpu_system_seconds_total', 'spark.memory.offHeap.enabled']
['container_cpu_system_seconds_total', 'spark.memory.offHeap.size']
['container_cpu_system_seconds_total', 'spark.executor.instances']
['container_cpu_system_seconds_total', 'spark.python.worker.memory']
['container_cpu_system_seconds_total', 'spark.python.worker.reuse']
['container_cpu_system_seconds_total', 'spark.rpc.message.maxSize']
['container_cpu_system_seconds_total', 'spark.driver.maxResultSize']
['container_cpu_system_seconds_total', 'spark.driver.memoryOverhead']
['container_cpu_system_seconds_total', 'spark.reducer.maxReqsInFlight']
['container_cpu_system_seconds_total', 'spark.reducer.maxBlocksInFlightPerAddress']
['container_cpu_system_seconds_total', 'spark.maxRemoteBlockSizeFetchToMem']
['container_cpu_system_seconds_total', 'spark.shuffle.io.maxRetries']
['container_cpu_system_seconds_total', 'spark.shuffle.io.numConnectionsPerPeer']
['container_cpu_system_seconds_total', 'spark.shuffle.io.preferDirectBufs']
['container_cpu_system_seconds_total', 'spark.shuffle.io.backLog']
['container_cpu_system_seconds_total', 'spark.shuffle.service.index.cache.size']
['container_cpu_system_seconds_total', 'spark.shuffle.maxChunksBeingTransferred']
['container_cpu_system_seconds_total', 'spark.serializer.objectStreamReset']
['container_cpu_system_seconds_total', 'spark.memory.useLegacyMode']
['container_cpu_system_seconds_total', 'spark.storage.replication.proactive']
['container_cpu_system_seconds_total', 'spark.cleaner.periodicGC.interval']
['container_cpu_system_seconds_total', 'spark.cleaner.referenceTracking']
['container_cpu_system_seconds_total', 'spark.cleaner.referenceTracking.blocking']
['container_cpu_system_seconds_total', 'spark.cleaner.referenceTracking.blocking.shuffle']
['container_cpu_system_seconds_total', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['container_cpu_system_seconds_total', 'spark.broadcast.checksum']
['container_cpu_system_seconds_total', 'spark.executor.heartbeatInterval']
['container_cpu_system_seconds_total', 'spark.files.fetchTimeout']
['container_cpu_system_seconds_total', 'spark.files.useFetchCache']
['container_cpu_system_seconds_total', 'spark.files.overwrite']
['container_cpu_system_seconds_total', 'spark.files.maxPartitionBytes']
['container_cpu_system_seconds_total', 'spark.files.openCostInBytes']
['container_cpu_system_seconds_total', 'spark.storage.memoryMapThreshold.1']
['container_cpu_system_seconds_total', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['container_cpu_system_seconds_total', 'spark.rpc.io.backLog']
['container_cpu_system_seconds_total', 'spark.port.maxRetries']
['container_cpu_system_seconds_total', 'spark.rpc.numRetries']
['container_cpu_system_seconds_total', 'spark.rpc.retry.wait']
['container_cpu_system_seconds_total', 'spark.rpc.lookupTimeout']
['container_cpu_system_seconds_total', 'spark.scheduler.minRegisteredResourcesRatio']
['container_cpu_system_seconds_total', 'spark.scheduler.mode']
['container_cpu_system_seconds_total', 'spark.scheduler.listenerbus.eventqueue.capacity']
['container_cpu_system_seconds_total', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['container_cpu_system_seconds_total', 'spark.task.reaper.enabled']
['container_cpu_system_seconds_total', 'spark.task.reaper.pollingInterval']
['container_cpu_system_seconds_total', 'spark.task.reaper.threadDump']
['container_cpu_system_seconds_total', 'spark.stage.maxConsecutiveAttempts']
['container_cpu_system_seconds_total', 'spark.streaming.backpressure.enabled']
['container_cpu_system_seconds_total', 'spark.streaming.blockInterval']
['container_cpu_system_seconds_total', 'spark.streaming.receiver.writeAheadLog.enable']
['container_cpu_system_seconds_total', 'spark.streaming.unpersist']
['container_cpu_system_seconds_total', 'spark.streaming.stopGracefullyOnShutdown']
['topdown-recovery-bubbles', 'spark.reducer.maxSizeInFlight']
['topdown-recovery-bubbles', 'spark.shuffle.file.buffer']
['topdown-recovery-bubbles', 'spark.shuffle.memoryFraction']
['topdown-recovery-bubbles', 'spark.shuffle.sort.bypassMergeThreshold']
['topdown-recovery-bubbles', 'spark.speculation.interval']
['topdown-recovery-bubbles', 'spark.speculation.multiplier']
['topdown-recovery-bubbles', 'spark.speculation.quantile']
['topdown-recovery-bubbles', 'spark.broadcast.blockSize']
['topdown-recovery-bubbles', 'spark.io.compression.codec']
['topdown-recovery-bubbles', 'spark.io.compression.lz4.blockSize']
['topdown-recovery-bubbles', 'spark.io.compression.snappy.blockSize']
['topdown-recovery-bubbles', 'spark.kryo.referenceTracking']
['topdown-recovery-bubbles', 'spark.kryoserializer.buffer.max']
['topdown-recovery-bubbles', 'spark.kryoserializer.buffer']
['topdown-recovery-bubbles', 'spark.driver.cores']
['topdown-recovery-bubbles', 'spark.executor.cores']
['topdown-recovery-bubbles', 'spark.driver.memory']
['topdown-recovery-bubbles', 'spark.executor.memory']
['topdown-recovery-bubbles', 'spark.storage.memoryFraction']
['topdown-recovery-bubbles', 'spark.storage.memoryMapThreshold']
['topdown-recovery-bubbles', 'spark.storage.unrollFraction']
['topdown-recovery-bubbles', 'spark.network.timeout']
['topdown-recovery-bubbles', 'spark.locality.wait']
['topdown-recovery-bubbles', 'spark.scheduler.revive.interval']
['topdown-recovery-bubbles', 'spark.task.maxFailures']
['topdown-recovery-bubbles', 'spark.shuffle.compress']
['topdown-recovery-bubbles', 'spark.memory.fraction']
['topdown-recovery-bubbles', 'spark.shuffle.spill.compress']
['topdown-recovery-bubbles', 'spark.speculation']
['topdown-recovery-bubbles', 'spark.broadcast.compress']
['topdown-recovery-bubbles', 'spark.rdd.compress']
['topdown-recovery-bubbles', 'spark.serializer']
['topdown-recovery-bubbles', 'spark.memory.storageFraction']
['topdown-recovery-bubbles', 'spark.default.parallelism']
['topdown-recovery-bubbles', 'spark.memory.offHeap.enabled']
['topdown-recovery-bubbles', 'spark.memory.offHeap.size']
['topdown-recovery-bubbles', 'spark.executor.instances']
['topdown-recovery-bubbles', 'spark.python.worker.memory']
['topdown-recovery-bubbles', 'spark.python.worker.reuse']
['topdown-recovery-bubbles', 'spark.rpc.message.maxSize']
['topdown-recovery-bubbles', 'spark.driver.maxResultSize']
['topdown-recovery-bubbles', 'spark.driver.memoryOverhead']
['topdown-recovery-bubbles', 'spark.reducer.maxReqsInFlight']
['topdown-recovery-bubbles', 'spark.reducer.maxBlocksInFlightPerAddress']
['topdown-recovery-bubbles', 'spark.maxRemoteBlockSizeFetchToMem']
['topdown-recovery-bubbles', 'spark.shuffle.io.maxRetries']
['topdown-recovery-bubbles', 'spark.shuffle.io.numConnectionsPerPeer']
['topdown-recovery-bubbles', 'spark.shuffle.io.preferDirectBufs']
['topdown-recovery-bubbles', 'spark.shuffle.io.backLog']
['topdown-recovery-bubbles', 'spark.shuffle.service.index.cache.size']
['topdown-recovery-bubbles', 'spark.shuffle.maxChunksBeingTransferred']
['topdown-recovery-bubbles', 'spark.serializer.objectStreamReset']
['topdown-recovery-bubbles', 'spark.memory.useLegacyMode']
['topdown-recovery-bubbles', 'spark.storage.replication.proactive']
['topdown-recovery-bubbles', 'spark.cleaner.periodicGC.interval']
['topdown-recovery-bubbles', 'spark.cleaner.referenceTracking']
['topdown-recovery-bubbles', 'spark.cleaner.referenceTracking.blocking']
['topdown-recovery-bubbles', 'spark.cleaner.referenceTracking.blocking.shuffle']
['topdown-recovery-bubbles', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['topdown-recovery-bubbles', 'spark.broadcast.checksum']
['topdown-recovery-bubbles', 'spark.executor.heartbeatInterval']
['topdown-recovery-bubbles', 'spark.files.fetchTimeout']
['topdown-recovery-bubbles', 'spark.files.useFetchCache']
['topdown-recovery-bubbles', 'spark.files.overwrite']
['topdown-recovery-bubbles', 'spark.files.maxPartitionBytes']
['topdown-recovery-bubbles', 'spark.files.openCostInBytes']
['topdown-recovery-bubbles', 'spark.storage.memoryMapThreshold.1']
['topdown-recovery-bubbles', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['topdown-recovery-bubbles', 'spark.rpc.io.backLog']
['topdown-recovery-bubbles', 'spark.port.maxRetries']
['topdown-recovery-bubbles', 'spark.rpc.numRetries']
['topdown-recovery-bubbles', 'spark.rpc.retry.wait']
['topdown-recovery-bubbles', 'spark.rpc.lookupTimeout']
['topdown-recovery-bubbles', 'spark.scheduler.minRegisteredResourcesRatio']
['topdown-recovery-bubbles', 'spark.scheduler.mode']
['topdown-recovery-bubbles', 'spark.scheduler.listenerbus.eventqueue.capacity']
['topdown-recovery-bubbles', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['topdown-recovery-bubbles', 'spark.task.reaper.enabled']
['topdown-recovery-bubbles', 'spark.task.reaper.pollingInterval']
['topdown-recovery-bubbles', 'spark.task.reaper.threadDump']
['topdown-recovery-bubbles', 'spark.stage.maxConsecutiveAttempts']
['topdown-recovery-bubbles', 'spark.streaming.backpressure.enabled']
['topdown-recovery-bubbles', 'spark.streaming.blockInterval']
['topdown-recovery-bubbles', 'spark.streaming.receiver.writeAheadLog.enable']
['topdown-recovery-bubbles', 'spark.streaming.unpersist']
['topdown-recovery-bubbles', 'spark.streaming.stopGracefullyOnShutdown']
['branch-instructions', 'spark.reducer.maxSizeInFlight']
['branch-instructions', 'spark.shuffle.file.buffer']
['branch-instructions', 'spark.shuffle.memoryFraction']
['branch-instructions', 'spark.shuffle.sort.bypassMergeThreshold']
['branch-instructions', 'spark.speculation.interval']
['branch-instructions', 'spark.speculation.multiplier']
['branch-instructions', 'spark.speculation.quantile']
['branch-instructions', 'spark.broadcast.blockSize']
['branch-instructions', 'spark.io.compression.codec']
['branch-instructions', 'spark.io.compression.lz4.blockSize']
['branch-instructions', 'spark.io.compression.snappy.blockSize']
['branch-instructions', 'spark.kryo.referenceTracking']
['branch-instructions', 'spark.kryoserializer.buffer.max']
['branch-instructions', 'spark.kryoserializer.buffer']
['branch-instructions', 'spark.driver.cores']
['branch-instructions', 'spark.executor.cores']
['branch-instructions', 'spark.driver.memory']
['branch-instructions', 'spark.executor.memory']
['branch-instructions', 'spark.storage.memoryFraction']
['branch-instructions', 'spark.storage.memoryMapThreshold']
['branch-instructions', 'spark.storage.unrollFraction']
['branch-instructions', 'spark.network.timeout']
['branch-instructions', 'spark.locality.wait']
['branch-instructions', 'spark.scheduler.revive.interval']
['branch-instructions', 'spark.task.maxFailures']
['branch-instructions', 'spark.shuffle.compress']
['branch-instructions', 'spark.memory.fraction']
['branch-instructions', 'spark.shuffle.spill.compress']
['branch-instructions', 'spark.speculation']
['branch-instructions', 'spark.broadcast.compress']
['branch-instructions', 'spark.rdd.compress']
['branch-instructions', 'spark.serializer']
['branch-instructions', 'spark.memory.storageFraction']
['branch-instructions', 'spark.default.parallelism']
['branch-instructions', 'spark.memory.offHeap.enabled']
['branch-instructions', 'spark.memory.offHeap.size']
['branch-instructions', 'spark.executor.instances']
['branch-instructions', 'spark.python.worker.memory']
['branch-instructions', 'spark.python.worker.reuse']
['branch-instructions', 'spark.rpc.message.maxSize']
['branch-instructions', 'spark.driver.maxResultSize']
['branch-instructions', 'spark.driver.memoryOverhead']
['branch-instructions', 'spark.reducer.maxReqsInFlight']
['branch-instructions', 'spark.reducer.maxBlocksInFlightPerAddress']
['branch-instructions', 'spark.maxRemoteBlockSizeFetchToMem']
['branch-instructions', 'spark.shuffle.io.maxRetries']
['branch-instructions', 'spark.shuffle.io.numConnectionsPerPeer']
['branch-instructions', 'spark.shuffle.io.preferDirectBufs']
['branch-instructions', 'spark.shuffle.io.backLog']
['branch-instructions', 'spark.shuffle.service.index.cache.size']
['branch-instructions', 'spark.shuffle.maxChunksBeingTransferred']
['branch-instructions', 'spark.serializer.objectStreamReset']
['branch-instructions', 'spark.memory.useLegacyMode']
['branch-instructions', 'spark.storage.replication.proactive']
['branch-instructions', 'spark.cleaner.periodicGC.interval']
['branch-instructions', 'spark.cleaner.referenceTracking']
['branch-instructions', 'spark.cleaner.referenceTracking.blocking']
['branch-instructions', 'spark.cleaner.referenceTracking.blocking.shuffle']
['branch-instructions', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['branch-instructions', 'spark.broadcast.checksum']
['branch-instructions', 'spark.executor.heartbeatInterval']
['branch-instructions', 'spark.files.fetchTimeout']
['branch-instructions', 'spark.files.useFetchCache']
['branch-instructions', 'spark.files.overwrite']
['branch-instructions', 'spark.files.maxPartitionBytes']
['branch-instructions', 'spark.files.openCostInBytes']
['branch-instructions', 'spark.storage.memoryMapThreshold.1']
['branch-instructions', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['branch-instructions', 'spark.rpc.io.backLog']
['branch-instructions', 'spark.port.maxRetries']
['branch-instructions', 'spark.rpc.numRetries']
['branch-instructions', 'spark.rpc.retry.wait']
['branch-instructions', 'spark.rpc.lookupTimeout']
['branch-instructions', 'spark.scheduler.minRegisteredResourcesRatio']
['branch-instructions', 'spark.scheduler.mode']
['branch-instructions', 'spark.scheduler.listenerbus.eventqueue.capacity']
['branch-instructions', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['branch-instructions', 'spark.task.reaper.enabled']
['branch-instructions', 'spark.task.reaper.pollingInterval']
['branch-instructions', 'spark.task.reaper.threadDump']
['branch-instructions', 'spark.stage.maxConsecutiveAttempts']
['branch-instructions', 'spark.streaming.backpressure.enabled']
['branch-instructions', 'spark.streaming.blockInterval']
['branch-instructions', 'spark.streaming.receiver.writeAheadLog.enable']
['branch-instructions', 'spark.streaming.unpersist']
['branch-instructions', 'spark.streaming.stopGracefullyOnShutdown']
['memory usage - used', 'spark.reducer.maxSizeInFlight']
['memory usage - used', 'spark.shuffle.file.buffer']
['memory usage - used', 'spark.shuffle.memoryFraction']
['memory usage - used', 'spark.shuffle.sort.bypassMergeThreshold']
['memory usage - used', 'spark.speculation.interval']
['memory usage - used', 'spark.speculation.multiplier']
['memory usage - used', 'spark.speculation.quantile']
['memory usage - used', 'spark.broadcast.blockSize']
['memory usage - used', 'spark.io.compression.codec']
['memory usage - used', 'spark.io.compression.lz4.blockSize']
['memory usage - used', 'spark.io.compression.snappy.blockSize']
['memory usage - used', 'spark.kryo.referenceTracking']
['memory usage - used', 'spark.kryoserializer.buffer.max']
['memory usage - used', 'spark.kryoserializer.buffer']
['memory usage - used', 'spark.driver.cores']
['memory usage - used', 'spark.executor.cores']
['memory usage - used', 'spark.driver.memory']
['memory usage - used', 'spark.executor.memory']
['memory usage - used', 'spark.storage.memoryFraction']
['memory usage - used', 'spark.storage.memoryMapThreshold']
['memory usage - used', 'spark.storage.unrollFraction']
['memory usage - used', 'spark.network.timeout']
['memory usage - used', 'spark.locality.wait']
['memory usage - used', 'spark.scheduler.revive.interval']
['memory usage - used', 'spark.task.maxFailures']
['memory usage - used', 'spark.shuffle.compress']
['memory usage - used', 'spark.memory.fraction']
['memory usage - used', 'spark.shuffle.spill.compress']
['memory usage - used', 'spark.speculation']
['memory usage - used', 'spark.broadcast.compress']
['memory usage - used', 'spark.rdd.compress']
['memory usage - used', 'spark.serializer']
['memory usage - used', 'spark.memory.storageFraction']
['memory usage - used', 'spark.default.parallelism']
['memory usage - used', 'spark.memory.offHeap.enabled']
['memory usage - used', 'spark.memory.offHeap.size']
['memory usage - used', 'spark.executor.instances']
['memory usage - used', 'spark.python.worker.memory']
['memory usage - used', 'spark.python.worker.reuse']
['memory usage - used', 'spark.rpc.message.maxSize']
['memory usage - used', 'spark.driver.maxResultSize']
['memory usage - used', 'spark.driver.memoryOverhead']
['memory usage - used', 'spark.reducer.maxReqsInFlight']
['memory usage - used', 'spark.reducer.maxBlocksInFlightPerAddress']
['memory usage - used', 'spark.maxRemoteBlockSizeFetchToMem']
['memory usage - used', 'spark.shuffle.io.maxRetries']
['memory usage - used', 'spark.shuffle.io.numConnectionsPerPeer']
['memory usage - used', 'spark.shuffle.io.preferDirectBufs']
['memory usage - used', 'spark.shuffle.io.backLog']
['memory usage - used', 'spark.shuffle.service.index.cache.size']
['memory usage - used', 'spark.shuffle.maxChunksBeingTransferred']
['memory usage - used', 'spark.serializer.objectStreamReset']
['memory usage - used', 'spark.memory.useLegacyMode']
['memory usage - used', 'spark.storage.replication.proactive']
['memory usage - used', 'spark.cleaner.periodicGC.interval']
['memory usage - used', 'spark.cleaner.referenceTracking']
['memory usage - used', 'spark.cleaner.referenceTracking.blocking']
['memory usage - used', 'spark.cleaner.referenceTracking.blocking.shuffle']
['memory usage - used', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['memory usage - used', 'spark.broadcast.checksum']
['memory usage - used', 'spark.executor.heartbeatInterval']
['memory usage - used', 'spark.files.fetchTimeout']
['memory usage - used', 'spark.files.useFetchCache']
['memory usage - used', 'spark.files.overwrite']
['memory usage - used', 'spark.files.maxPartitionBytes']
['memory usage - used', 'spark.files.openCostInBytes']
['memory usage - used', 'spark.storage.memoryMapThreshold.1']
['memory usage - used', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['memory usage - used', 'spark.rpc.io.backLog']
['memory usage - used', 'spark.port.maxRetries']
['memory usage - used', 'spark.rpc.numRetries']
['memory usage - used', 'spark.rpc.retry.wait']
['memory usage - used', 'spark.rpc.lookupTimeout']
['memory usage - used', 'spark.scheduler.minRegisteredResourcesRatio']
['memory usage - used', 'spark.scheduler.mode']
['memory usage - used', 'spark.scheduler.listenerbus.eventqueue.capacity']
['memory usage - used', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['memory usage - used', 'spark.task.reaper.enabled']
['memory usage - used', 'spark.task.reaper.pollingInterval']
['memory usage - used', 'spark.task.reaper.threadDump']
['memory usage - used', 'spark.stage.maxConsecutiveAttempts']
['memory usage - used', 'spark.streaming.backpressure.enabled']
['memory usage - used', 'spark.streaming.blockInterval']
['memory usage - used', 'spark.streaming.receiver.writeAheadLog.enable']
['memory usage - used', 'spark.streaming.unpersist']
['memory usage - used', 'spark.streaming.stopGracefullyOnShutdown']
['exe_activity.4_ports_util', 'spark.reducer.maxSizeInFlight']
['exe_activity.4_ports_util', 'spark.shuffle.file.buffer']
['exe_activity.4_ports_util', 'spark.shuffle.memoryFraction']
['exe_activity.4_ports_util', 'spark.shuffle.sort.bypassMergeThreshold']
['exe_activity.4_ports_util', 'spark.speculation.interval']
['exe_activity.4_ports_util', 'spark.speculation.multiplier']
['exe_activity.4_ports_util', 'spark.speculation.quantile']
['exe_activity.4_ports_util', 'spark.broadcast.blockSize']
['exe_activity.4_ports_util', 'spark.io.compression.codec']
['exe_activity.4_ports_util', 'spark.io.compression.lz4.blockSize']
['exe_activity.4_ports_util', 'spark.io.compression.snappy.blockSize']
['exe_activity.4_ports_util', 'spark.kryo.referenceTracking']
['exe_activity.4_ports_util', 'spark.kryoserializer.buffer.max']
['exe_activity.4_ports_util', 'spark.kryoserializer.buffer']
['exe_activity.4_ports_util', 'spark.driver.cores']
['exe_activity.4_ports_util', 'spark.executor.cores']
['exe_activity.4_ports_util', 'spark.driver.memory']
['exe_activity.4_ports_util', 'spark.executor.memory']
['exe_activity.4_ports_util', 'spark.storage.memoryFraction']
['exe_activity.4_ports_util', 'spark.storage.memoryMapThreshold']
['exe_activity.4_ports_util', 'spark.storage.unrollFraction']
['exe_activity.4_ports_util', 'spark.network.timeout']
['exe_activity.4_ports_util', 'spark.locality.wait']
['exe_activity.4_ports_util', 'spark.scheduler.revive.interval']
['exe_activity.4_ports_util', 'spark.task.maxFailures']
['exe_activity.4_ports_util', 'spark.shuffle.compress']
['exe_activity.4_ports_util', 'spark.memory.fraction']
['exe_activity.4_ports_util', 'spark.shuffle.spill.compress']
['exe_activity.4_ports_util', 'spark.speculation']
['exe_activity.4_ports_util', 'spark.broadcast.compress']
['exe_activity.4_ports_util', 'spark.rdd.compress']
['exe_activity.4_ports_util', 'spark.serializer']
['exe_activity.4_ports_util', 'spark.memory.storageFraction']
['exe_activity.4_ports_util', 'spark.default.parallelism']
['exe_activity.4_ports_util', 'spark.memory.offHeap.enabled']
['exe_activity.4_ports_util', 'spark.memory.offHeap.size']
['exe_activity.4_ports_util', 'spark.executor.instances']
['exe_activity.4_ports_util', 'spark.python.worker.memory']
['exe_activity.4_ports_util', 'spark.python.worker.reuse']
['exe_activity.4_ports_util', 'spark.rpc.message.maxSize']
['exe_activity.4_ports_util', 'spark.driver.maxResultSize']
['exe_activity.4_ports_util', 'spark.driver.memoryOverhead']
['exe_activity.4_ports_util', 'spark.reducer.maxReqsInFlight']
['exe_activity.4_ports_util', 'spark.reducer.maxBlocksInFlightPerAddress']
['exe_activity.4_ports_util', 'spark.maxRemoteBlockSizeFetchToMem']
['exe_activity.4_ports_util', 'spark.shuffle.io.maxRetries']
['exe_activity.4_ports_util', 'spark.shuffle.io.numConnectionsPerPeer']
['exe_activity.4_ports_util', 'spark.shuffle.io.preferDirectBufs']
['exe_activity.4_ports_util', 'spark.shuffle.io.backLog']
['exe_activity.4_ports_util', 'spark.shuffle.service.index.cache.size']
['exe_activity.4_ports_util', 'spark.shuffle.maxChunksBeingTransferred']
['exe_activity.4_ports_util', 'spark.serializer.objectStreamReset']
['exe_activity.4_ports_util', 'spark.memory.useLegacyMode']
['exe_activity.4_ports_util', 'spark.storage.replication.proactive']
['exe_activity.4_ports_util', 'spark.cleaner.periodicGC.interval']
['exe_activity.4_ports_util', 'spark.cleaner.referenceTracking']
['exe_activity.4_ports_util', 'spark.cleaner.referenceTracking.blocking']
['exe_activity.4_ports_util', 'spark.cleaner.referenceTracking.blocking.shuffle']
['exe_activity.4_ports_util', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['exe_activity.4_ports_util', 'spark.broadcast.checksum']
['exe_activity.4_ports_util', 'spark.executor.heartbeatInterval']
['exe_activity.4_ports_util', 'spark.files.fetchTimeout']
['exe_activity.4_ports_util', 'spark.files.useFetchCache']
['exe_activity.4_ports_util', 'spark.files.overwrite']
['exe_activity.4_ports_util', 'spark.files.maxPartitionBytes']
['exe_activity.4_ports_util', 'spark.files.openCostInBytes']
['exe_activity.4_ports_util', 'spark.storage.memoryMapThreshold.1']
['exe_activity.4_ports_util', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['exe_activity.4_ports_util', 'spark.rpc.io.backLog']
['exe_activity.4_ports_util', 'spark.port.maxRetries']
['exe_activity.4_ports_util', 'spark.rpc.numRetries']
['exe_activity.4_ports_util', 'spark.rpc.retry.wait']
['exe_activity.4_ports_util', 'spark.rpc.lookupTimeout']
['exe_activity.4_ports_util', 'spark.scheduler.minRegisteredResourcesRatio']
['exe_activity.4_ports_util', 'spark.scheduler.mode']
['exe_activity.4_ports_util', 'spark.scheduler.listenerbus.eventqueue.capacity']
['exe_activity.4_ports_util', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['exe_activity.4_ports_util', 'spark.task.reaper.enabled']
['exe_activity.4_ports_util', 'spark.task.reaper.pollingInterval']
['exe_activity.4_ports_util', 'spark.task.reaper.threadDump']
['exe_activity.4_ports_util', 'spark.stage.maxConsecutiveAttempts']
['exe_activity.4_ports_util', 'spark.streaming.backpressure.enabled']
['exe_activity.4_ports_util', 'spark.streaming.blockInterval']
['exe_activity.4_ports_util', 'spark.streaming.receiver.writeAheadLog.enable']
['exe_activity.4_ports_util', 'spark.streaming.unpersist']
['exe_activity.4_ports_util', 'spark.streaming.stopGracefullyOnShutdown']
['dTLB-loads', 'spark.reducer.maxSizeInFlight']
['dTLB-loads', 'spark.shuffle.file.buffer']
['dTLB-loads', 'spark.shuffle.memoryFraction']
['dTLB-loads', 'spark.shuffle.sort.bypassMergeThreshold']
['dTLB-loads', 'spark.speculation.interval']
['dTLB-loads', 'spark.speculation.multiplier']
['dTLB-loads', 'spark.speculation.quantile']
['dTLB-loads', 'spark.broadcast.blockSize']
['dTLB-loads', 'spark.io.compression.codec']
['dTLB-loads', 'spark.io.compression.lz4.blockSize']
['dTLB-loads', 'spark.io.compression.snappy.blockSize']
['dTLB-loads', 'spark.kryo.referenceTracking']
['dTLB-loads', 'spark.kryoserializer.buffer.max']
['dTLB-loads', 'spark.kryoserializer.buffer']
['dTLB-loads', 'spark.driver.cores']
['dTLB-loads', 'spark.executor.cores']
['dTLB-loads', 'spark.driver.memory']
['dTLB-loads', 'spark.executor.memory']
['dTLB-loads', 'spark.storage.memoryFraction']
['dTLB-loads', 'spark.storage.memoryMapThreshold']
['dTLB-loads', 'spark.storage.unrollFraction']
['dTLB-loads', 'spark.network.timeout']
['dTLB-loads', 'spark.locality.wait']
['dTLB-loads', 'spark.scheduler.revive.interval']
['dTLB-loads', 'spark.task.maxFailures']
['dTLB-loads', 'spark.shuffle.compress']
['dTLB-loads', 'spark.memory.fraction']
['dTLB-loads', 'spark.shuffle.spill.compress']
['dTLB-loads', 'spark.speculation']
['dTLB-loads', 'spark.broadcast.compress']
['dTLB-loads', 'spark.rdd.compress']
['dTLB-loads', 'spark.serializer']
['dTLB-loads', 'spark.memory.storageFraction']
['dTLB-loads', 'spark.default.parallelism']
['dTLB-loads', 'spark.memory.offHeap.enabled']
['dTLB-loads', 'spark.memory.offHeap.size']
['dTLB-loads', 'spark.executor.instances']
['dTLB-loads', 'spark.python.worker.memory']
['dTLB-loads', 'spark.python.worker.reuse']
['dTLB-loads', 'spark.rpc.message.maxSize']
['dTLB-loads', 'spark.driver.maxResultSize']
['dTLB-loads', 'spark.driver.memoryOverhead']
['dTLB-loads', 'spark.reducer.maxReqsInFlight']
['dTLB-loads', 'spark.reducer.maxBlocksInFlightPerAddress']
['dTLB-loads', 'spark.maxRemoteBlockSizeFetchToMem']
['dTLB-loads', 'spark.shuffle.io.maxRetries']
['dTLB-loads', 'spark.shuffle.io.numConnectionsPerPeer']
['dTLB-loads', 'spark.shuffle.io.preferDirectBufs']
['dTLB-loads', 'spark.shuffle.io.backLog']
['dTLB-loads', 'spark.shuffle.service.index.cache.size']
['dTLB-loads', 'spark.shuffle.maxChunksBeingTransferred']
['dTLB-loads', 'spark.serializer.objectStreamReset']
['dTLB-loads', 'spark.memory.useLegacyMode']
['dTLB-loads', 'spark.storage.replication.proactive']
['dTLB-loads', 'spark.cleaner.periodicGC.interval']
['dTLB-loads', 'spark.cleaner.referenceTracking']
['dTLB-loads', 'spark.cleaner.referenceTracking.blocking']
['dTLB-loads', 'spark.cleaner.referenceTracking.blocking.shuffle']
['dTLB-loads', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['dTLB-loads', 'spark.broadcast.checksum']
['dTLB-loads', 'spark.executor.heartbeatInterval']
['dTLB-loads', 'spark.files.fetchTimeout']
['dTLB-loads', 'spark.files.useFetchCache']
['dTLB-loads', 'spark.files.overwrite']
['dTLB-loads', 'spark.files.maxPartitionBytes']
['dTLB-loads', 'spark.files.openCostInBytes']
['dTLB-loads', 'spark.storage.memoryMapThreshold.1']
['dTLB-loads', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['dTLB-loads', 'spark.rpc.io.backLog']
['dTLB-loads', 'spark.port.maxRetries']
['dTLB-loads', 'spark.rpc.numRetries']
['dTLB-loads', 'spark.rpc.retry.wait']
['dTLB-loads', 'spark.rpc.lookupTimeout']
['dTLB-loads', 'spark.scheduler.minRegisteredResourcesRatio']
['dTLB-loads', 'spark.scheduler.mode']
['dTLB-loads', 'spark.scheduler.listenerbus.eventqueue.capacity']
['dTLB-loads', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['dTLB-loads', 'spark.task.reaper.enabled']
['dTLB-loads', 'spark.task.reaper.pollingInterval']
['dTLB-loads', 'spark.task.reaper.threadDump']
['dTLB-loads', 'spark.stage.maxConsecutiveAttempts']
['dTLB-loads', 'spark.streaming.backpressure.enabled']
['dTLB-loads', 'spark.streaming.blockInterval']
['dTLB-loads', 'spark.streaming.receiver.writeAheadLog.enable']
['dTLB-loads', 'spark.streaming.unpersist']
['dTLB-loads', 'spark.streaming.stopGracefullyOnShutdown']
['frontend_retired.itlb_miss', 'spark.reducer.maxSizeInFlight']
['frontend_retired.itlb_miss', 'spark.shuffle.file.buffer']
['frontend_retired.itlb_miss', 'spark.shuffle.memoryFraction']
['frontend_retired.itlb_miss', 'spark.shuffle.sort.bypassMergeThreshold']
['frontend_retired.itlb_miss', 'spark.speculation.interval']
['frontend_retired.itlb_miss', 'spark.speculation.multiplier']
['frontend_retired.itlb_miss', 'spark.speculation.quantile']
['frontend_retired.itlb_miss', 'spark.broadcast.blockSize']
['frontend_retired.itlb_miss', 'spark.io.compression.codec']
['frontend_retired.itlb_miss', 'spark.io.compression.lz4.blockSize']
['frontend_retired.itlb_miss', 'spark.io.compression.snappy.blockSize']
['frontend_retired.itlb_miss', 'spark.kryo.referenceTracking']
['frontend_retired.itlb_miss', 'spark.kryoserializer.buffer.max']
['frontend_retired.itlb_miss', 'spark.kryoserializer.buffer']
['frontend_retired.itlb_miss', 'spark.driver.cores']
['frontend_retired.itlb_miss', 'spark.executor.cores']
['frontend_retired.itlb_miss', 'spark.driver.memory']
['frontend_retired.itlb_miss', 'spark.executor.memory']
['frontend_retired.itlb_miss', 'spark.storage.memoryFraction']
['frontend_retired.itlb_miss', 'spark.storage.memoryMapThreshold']
['frontend_retired.itlb_miss', 'spark.storage.unrollFraction']
['frontend_retired.itlb_miss', 'spark.network.timeout']
['frontend_retired.itlb_miss', 'spark.locality.wait']
['frontend_retired.itlb_miss', 'spark.scheduler.revive.interval']
['frontend_retired.itlb_miss', 'spark.task.maxFailures']
['frontend_retired.itlb_miss', 'spark.shuffle.compress']
['frontend_retired.itlb_miss', 'spark.memory.fraction']
['frontend_retired.itlb_miss', 'spark.shuffle.spill.compress']
['frontend_retired.itlb_miss', 'spark.speculation']
['frontend_retired.itlb_miss', 'spark.broadcast.compress']
['frontend_retired.itlb_miss', 'spark.rdd.compress']
['frontend_retired.itlb_miss', 'spark.serializer']
['frontend_retired.itlb_miss', 'spark.memory.storageFraction']
['frontend_retired.itlb_miss', 'spark.default.parallelism']
['frontend_retired.itlb_miss', 'spark.memory.offHeap.enabled']
['frontend_retired.itlb_miss', 'spark.memory.offHeap.size']
['frontend_retired.itlb_miss', 'spark.executor.instances']
['frontend_retired.itlb_miss', 'spark.python.worker.memory']
['frontend_retired.itlb_miss', 'spark.python.worker.reuse']
['frontend_retired.itlb_miss', 'spark.rpc.message.maxSize']
['frontend_retired.itlb_miss', 'spark.driver.maxResultSize']
['frontend_retired.itlb_miss', 'spark.driver.memoryOverhead']
['frontend_retired.itlb_miss', 'spark.reducer.maxReqsInFlight']
['frontend_retired.itlb_miss', 'spark.reducer.maxBlocksInFlightPerAddress']
['frontend_retired.itlb_miss', 'spark.maxRemoteBlockSizeFetchToMem']
['frontend_retired.itlb_miss', 'spark.shuffle.io.maxRetries']
['frontend_retired.itlb_miss', 'spark.shuffle.io.numConnectionsPerPeer']
['frontend_retired.itlb_miss', 'spark.shuffle.io.preferDirectBufs']
['frontend_retired.itlb_miss', 'spark.shuffle.io.backLog']
['frontend_retired.itlb_miss', 'spark.shuffle.service.index.cache.size']
['frontend_retired.itlb_miss', 'spark.shuffle.maxChunksBeingTransferred']
['frontend_retired.itlb_miss', 'spark.serializer.objectStreamReset']
['frontend_retired.itlb_miss', 'spark.memory.useLegacyMode']
['frontend_retired.itlb_miss', 'spark.storage.replication.proactive']
['frontend_retired.itlb_miss', 'spark.cleaner.periodicGC.interval']
['frontend_retired.itlb_miss', 'spark.cleaner.referenceTracking']
['frontend_retired.itlb_miss', 'spark.cleaner.referenceTracking.blocking']
['frontend_retired.itlb_miss', 'spark.cleaner.referenceTracking.blocking.shuffle']
['frontend_retired.itlb_miss', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['frontend_retired.itlb_miss', 'spark.broadcast.checksum']
['frontend_retired.itlb_miss', 'spark.executor.heartbeatInterval']
['frontend_retired.itlb_miss', 'spark.files.fetchTimeout']
['frontend_retired.itlb_miss', 'spark.files.useFetchCache']
['frontend_retired.itlb_miss', 'spark.files.overwrite']
['frontend_retired.itlb_miss', 'spark.files.maxPartitionBytes']
['frontend_retired.itlb_miss', 'spark.files.openCostInBytes']
['frontend_retired.itlb_miss', 'spark.storage.memoryMapThreshold.1']
['frontend_retired.itlb_miss', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['frontend_retired.itlb_miss', 'spark.rpc.io.backLog']
['frontend_retired.itlb_miss', 'spark.port.maxRetries']
['frontend_retired.itlb_miss', 'spark.rpc.numRetries']
['frontend_retired.itlb_miss', 'spark.rpc.retry.wait']
['frontend_retired.itlb_miss', 'spark.rpc.lookupTimeout']
['frontend_retired.itlb_miss', 'spark.scheduler.minRegisteredResourcesRatio']
['frontend_retired.itlb_miss', 'spark.scheduler.mode']
['frontend_retired.itlb_miss', 'spark.scheduler.listenerbus.eventqueue.capacity']
['frontend_retired.itlb_miss', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['frontend_retired.itlb_miss', 'spark.task.reaper.enabled']
['frontend_retired.itlb_miss', 'spark.task.reaper.pollingInterval']
['frontend_retired.itlb_miss', 'spark.task.reaper.threadDump']
['frontend_retired.itlb_miss', 'spark.stage.maxConsecutiveAttempts']
['frontend_retired.itlb_miss', 'spark.streaming.backpressure.enabled']
['frontend_retired.itlb_miss', 'spark.streaming.blockInterval']
['frontend_retired.itlb_miss', 'spark.streaming.receiver.writeAheadLog.enable']
['frontend_retired.itlb_miss', 'spark.streaming.unpersist']
['frontend_retired.itlb_miss', 'spark.streaming.stopGracefullyOnShutdown']
['frontend_retired.stlb_miss', 'spark.reducer.maxSizeInFlight']
['frontend_retired.stlb_miss', 'spark.shuffle.file.buffer']
['frontend_retired.stlb_miss', 'spark.shuffle.memoryFraction']
['frontend_retired.stlb_miss', 'spark.shuffle.sort.bypassMergeThreshold']
['frontend_retired.stlb_miss', 'spark.speculation.interval']
['frontend_retired.stlb_miss', 'spark.speculation.multiplier']
['frontend_retired.stlb_miss', 'spark.speculation.quantile']
['frontend_retired.stlb_miss', 'spark.broadcast.blockSize']
['frontend_retired.stlb_miss', 'spark.io.compression.codec']
['frontend_retired.stlb_miss', 'spark.io.compression.lz4.blockSize']
['frontend_retired.stlb_miss', 'spark.io.compression.snappy.blockSize']
['frontend_retired.stlb_miss', 'spark.kryo.referenceTracking']
['frontend_retired.stlb_miss', 'spark.kryoserializer.buffer.max']
['frontend_retired.stlb_miss', 'spark.kryoserializer.buffer']
['frontend_retired.stlb_miss', 'spark.driver.cores']
['frontend_retired.stlb_miss', 'spark.executor.cores']
['frontend_retired.stlb_miss', 'spark.driver.memory']
['frontend_retired.stlb_miss', 'spark.executor.memory']
['frontend_retired.stlb_miss', 'spark.storage.memoryFraction']
['frontend_retired.stlb_miss', 'spark.storage.memoryMapThreshold']
['frontend_retired.stlb_miss', 'spark.storage.unrollFraction']
['frontend_retired.stlb_miss', 'spark.network.timeout']
['frontend_retired.stlb_miss', 'spark.locality.wait']
['frontend_retired.stlb_miss', 'spark.scheduler.revive.interval']
['frontend_retired.stlb_miss', 'spark.task.maxFailures']
['frontend_retired.stlb_miss', 'spark.shuffle.compress']
['frontend_retired.stlb_miss', 'spark.memory.fraction']
['frontend_retired.stlb_miss', 'spark.shuffle.spill.compress']
['frontend_retired.stlb_miss', 'spark.speculation']
['frontend_retired.stlb_miss', 'spark.broadcast.compress']
['frontend_retired.stlb_miss', 'spark.rdd.compress']
['frontend_retired.stlb_miss', 'spark.serializer']
['frontend_retired.stlb_miss', 'spark.memory.storageFraction']
['frontend_retired.stlb_miss', 'spark.default.parallelism']
['frontend_retired.stlb_miss', 'spark.memory.offHeap.enabled']
['frontend_retired.stlb_miss', 'spark.memory.offHeap.size']
['frontend_retired.stlb_miss', 'spark.executor.instances']
['frontend_retired.stlb_miss', 'spark.python.worker.memory']
['frontend_retired.stlb_miss', 'spark.python.worker.reuse']
['frontend_retired.stlb_miss', 'spark.rpc.message.maxSize']
['frontend_retired.stlb_miss', 'spark.driver.maxResultSize']
['frontend_retired.stlb_miss', 'spark.driver.memoryOverhead']
['frontend_retired.stlb_miss', 'spark.reducer.maxReqsInFlight']
['frontend_retired.stlb_miss', 'spark.reducer.maxBlocksInFlightPerAddress']
['frontend_retired.stlb_miss', 'spark.maxRemoteBlockSizeFetchToMem']
['frontend_retired.stlb_miss', 'spark.shuffle.io.maxRetries']
['frontend_retired.stlb_miss', 'spark.shuffle.io.numConnectionsPerPeer']
['frontend_retired.stlb_miss', 'spark.shuffle.io.preferDirectBufs']
['frontend_retired.stlb_miss', 'spark.shuffle.io.backLog']
['frontend_retired.stlb_miss', 'spark.shuffle.service.index.cache.size']
['frontend_retired.stlb_miss', 'spark.shuffle.maxChunksBeingTransferred']
['frontend_retired.stlb_miss', 'spark.serializer.objectStreamReset']
['frontend_retired.stlb_miss', 'spark.memory.useLegacyMode']
['frontend_retired.stlb_miss', 'spark.storage.replication.proactive']
['frontend_retired.stlb_miss', 'spark.cleaner.periodicGC.interval']
['frontend_retired.stlb_miss', 'spark.cleaner.referenceTracking']
['frontend_retired.stlb_miss', 'spark.cleaner.referenceTracking.blocking']
['frontend_retired.stlb_miss', 'spark.cleaner.referenceTracking.blocking.shuffle']
['frontend_retired.stlb_miss', 'spark.cleaner.referenceTracking.cleanCheckpoints']
['frontend_retired.stlb_miss', 'spark.broadcast.checksum']
['frontend_retired.stlb_miss', 'spark.executor.heartbeatInterval']
['frontend_retired.stlb_miss', 'spark.files.fetchTimeout']
['frontend_retired.stlb_miss', 'spark.files.useFetchCache']
['frontend_retired.stlb_miss', 'spark.files.overwrite']
['frontend_retired.stlb_miss', 'spark.files.maxPartitionBytes']
['frontend_retired.stlb_miss', 'spark.files.openCostInBytes']
['frontend_retired.stlb_miss', 'spark.storage.memoryMapThreshold.1']
['frontend_retired.stlb_miss', 'spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version']
['frontend_retired.stlb_miss', 'spark.rpc.io.backLog']
['frontend_retired.stlb_miss', 'spark.port.maxRetries']
['frontend_retired.stlb_miss', 'spark.rpc.numRetries']
['frontend_retired.stlb_miss', 'spark.rpc.retry.wait']
['frontend_retired.stlb_miss', 'spark.rpc.lookupTimeout']
['frontend_retired.stlb_miss', 'spark.scheduler.minRegisteredResourcesRatio']
['frontend_retired.stlb_miss', 'spark.scheduler.mode']
['frontend_retired.stlb_miss', 'spark.scheduler.listenerbus.eventqueue.capacity']
['frontend_retired.stlb_miss', 'spark.scheduler.blacklist.unschedulableTaskSetTimeout']
['frontend_retired.stlb_miss', 'spark.task.reaper.enabled']
['frontend_retired.stlb_miss', 'spark.task.reaper.pollingInterval']
['frontend_retired.stlb_miss', 'spark.task.reaper.threadDump']
['frontend_retired.stlb_miss', 'spark.stage.maxConsecutiveAttempts']
['frontend_retired.stlb_miss', 'spark.streaming.backpressure.enabled']
['frontend_retired.stlb_miss', 'spark.streaming.blockInterval']
['frontend_retired.stlb_miss', 'spark.streaming.receiver.writeAheadLog.enable']
['frontend_retired.stlb_miss', 'spark.streaming.unpersist']
['frontend_retired.stlb_miss', 'spark.streaming.stopGracefullyOnShutdown']
