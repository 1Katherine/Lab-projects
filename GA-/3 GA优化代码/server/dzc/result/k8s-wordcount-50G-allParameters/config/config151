# Fixed configuration
# Spark home
hibench.spark.home      /usr/local/home/spark/spark
# hibench.spark.master     yarn-client
hibench.spark.master    k8s://https://192.168.0.10:6443
spark.kubernetes.container.image     192.168.0.40/library/spark:v2.4.4

spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://192.168.0.10:9000/spark/log
spark.history.fs.logDirectory 	 hdfs://192.168.0.10:9000/spark/log
spark.eventLog.compress true

#======================================================
# Spark Streaming
#======================================================
# Spark streaming Batchnterval in millisecond (default 100)
hibench.streambench.spark.batchInterval          100

# Number of nodes that will receive kafka input (default: 4)
hibench.streambench.spark.receiverNumber        4

# Indicate RDD storage level. (default: 2)
# 0 = StorageLevel.MEMORY_ONLY
# 1 = StorageLevel.MEMORY_AND_DISK_SER
# other = StorageLevel.MEMORY_AND_DISK_SER_2
hibench.streambench.spark.storageLevel 2

# indicate whether to test the write ahead log new feature (default: false)
hibench.streambench.spark.enableWAL false

# if testWAL is true, this path to store stream context in hdfs shall be specified. If false, it can be empty (default: /var/tmp)
hibench.streambench.spark.checkpointPath /var/tmp

# whether to use direct approach or not (dafault: true)
hibench.streambench.spark.useDirectMode true


# Random configuration
 spark.broadcast.blockSize	431m
 spark.broadcast.checksum	true
 spark.broadcast.compress	false
 spark.cleaner.periodicGC.interval	39min
 spark.cleaner.referenceTracking	true
 spark.cleaner.referenceTracking.blocking	true
 spark.cleaner.referenceTracking.blocking.shuffle	false
 spark.cleaner.referenceTracking.cleanCheckpoints	false
 spark.default.parallelism	110
 spark.driver.cores	8
 spark.driver.maxResultSize	149m
 spark.driver.memory	20g
 spark.driver.memoryOverhead	1829M
 spark.executor.cores	10
 spark.executor.heartbeatInterval	5s
 spark.executor.instances	5
 spark.executor.memory	3g
 spark.files.fetchTimeout	90s
 spark.files.maxPartitionBytes	195383392
 spark.files.openCostInBytes	4265269
 spark.files.overwrite	true
 spark.files.useFetchCache	true
 spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version	1
 spark.io.compression.codec	lz4
 spark.io.compression.lz4.blockSize	192k
 spark.io.compression.snappy.blockSize	139k
 spark.kryo.referenceTracking	false
 spark.kryoserializer.buffer	93k
 spark.kryoserializer.buffer.max	94m
 spark.locality.wait	9s
 spark.maxRemoteBlockSizeFetchToMem	1060889678m
 spark.memory.fraction	0.52
 spark.memory.offHeap.enabled	true
 spark.memory.offHeap.size	745m
 spark.memory.storageFraction	0.69
 spark.memory.useLegacyMode	true
 spark.network.timeout	458s
 spark.port.maxRetries	5
 spark.python.worker.memory	724m
 spark.python.worker.reuse	true
 spark.rdd.compress	true
 spark.reducer.maxBlocksInFlightPerAddress	2121467761
 spark.reducer.maxReqsInFlight	329995822
 spark.reducer.maxSizeInFlight	20m
 spark.rpc.io.backLog	86
 spark.rpc.lookupTimeout	240s
 spark.rpc.message.maxSize	326
 spark.rpc.retry.wait	4s
 spark.scheduler.blacklist.unschedulableTaskSetTimeout	56s
 spark.scheduler.listenerbus.eventqueue.capacity	18466
 spark.scheduler.minRegisteredResourcesRatio	0.82
 spark.scheduler.mode	FIFO
 spark.scheduler.revive.interval	33s
 spark.serializer	org.apache.spark.serializer.KryoSerializer
 spark.serializer.objectStreamReset	263
 spark.shuffle.compress	false
 spark.shuffle.file.buffer	185k
 spark.shuffle.io.backLog	17
 spark.shuffle.io.maxRetries	10
 spark.shuffle.io.numConnectionsPerPeer	1
 spark.shuffle.io.preferDirectBufs	false
 spark.shuffle.maxChunksBeingTransferred	4445047306158485504
 spark.shuffle.memoryFraction	0.91
 spark.shuffle.service.index.cache.size	132m
 spark.shuffle.sort.bypassMergeThreshold	1000
 spark.shuffle.spill.compress	false
 spark.speculation	false
 spark.speculation.interval	1000ms
 spark.speculation.multiplier	4.41
 spark.speculation.quantile	0.67
 spark.stage.maxConsecutiveAttempts	6
 spark.storage.memoryFraction	0.09
 spark.storage.memoryMapThreshold	372m
 spark.storage.replication.proactive	true
 spark.storage.unrollFraction	0.31
 spark.streaming.backpressure.enabled	true
 spark.streaming.blockInterval	336ms
 spark.streaming.receiver.writeAheadLog.enable	false
 spark.streaming.stopGracefullyOnShutdown	true
 spark.streaming.unpersist	true
 spark.task.maxFailures	7
 spark.task.reaper.enabled	false
 spark.task.reaper.pollingInterval	20s
 spark.task.reaper.threadDump	true
